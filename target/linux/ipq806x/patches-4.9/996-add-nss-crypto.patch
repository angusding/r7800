From 5a717d35dbc9f9fb59ee039e7e43890d91292b2c Mon Sep 17 00:00:00 2001
From: Sourav Poddar <souravp@codeaurora.org>
Date: Wed, 15 Feb 2017 20:13:20 +0530
Subject: [qca-nss-crypto] Move current crypto driver to v1.0 folder

This patch moves the current crypto driver to v1.0 folder.
This v1.0/ version of crypto driver will be used on Akronite
till Akronite is not moved to new messaging interface.
There will be a similar v2.0/ folder created which is the
new messaging interface and will be used by ipq807x

Change-Id: I3e046853a4ac7806309c884b73592adbd0e6c633
Signed-off-by: Sourav Poddar <souravp@codeaurora.org>
---
 drivers/crypto/nss/Makefile              |   25 +
 drivers/crypto/nss/nss_crypto_ctrl.c     | 1282 ++++++++++++++++++++++++++++++++++++++++
 drivers/crypto/nss/nss_crypto_ctrl.h     |  269 +++++++++
 drivers/crypto/nss/nss_crypto_dbg.h      |  108 ++++
 drivers/crypto/nss/nss_crypto_debugfs.c  |  296 ++++++++++
 drivers/crypto/nss/nss_crypto_debugfs.h  |   49 ++
 drivers/crypto/nss/nss_crypto_dtsi.c     |  486 +++++++++++++++
 drivers/crypto/nss/nss_crypto_hlos.h     |   82 +++
 drivers/crypto/nss/nss_crypto_hw.h       |  296 ++++++++++
 drivers/crypto/nss/nss_crypto_if.c       |  738 +++++++++++++++++++++++
 drivers/crypto/nss/nss_crypto_platform.c |  296 ++++++++++
 11 files changed, 3927 insertions(+)
 create mode 100644 drivers/crypto/nss/Makefile
 create mode 100644 drivers/crypto/nss/nss_crypto_ctrl.c
 create mode 100644 drivers/crypto/nss/nss_crypto_ctrl.h
 create mode 100644 drivers/crypto/nss/nss_crypto_dbg.h
 create mode 100644 drivers/crypto/nss/nss_crypto_debugfs.c
 create mode 100644 drivers/crypto/nss/nss_crypto_debugfs.h
 create mode 100644 drivers/crypto/nss/nss_crypto_dtsi.c
 create mode 100644 drivers/crypto/nss/nss_crypto_hlos.h
 create mode 100644 drivers/crypto/nss/nss_crypto_hw.h
 create mode 100644 drivers/crypto/nss/nss_crypto_if.c
 create mode 100644 drivers/crypto/nss/nss_crypto_platform.c

(limited to 'drivers/crypto/nss')

diff --git a/drivers/crypto/nss/Makefile b/drivers/crypto/nss/Makefile
new file mode 100644
index 0000000..9a9f89e
--- /dev/null
+++ b/drivers/crypto/nss/Makefile
@@ -0,0 +1,25 @@
+# ###################################################
+# # Makefile for the NSS driver
+# ###################################################
+
+NSS_CRYPTO_MOD_NAME=qca-nss-crypto
+
+#ccflags-y += -DCONFIG_NSS_CRYPTO_DBG
+ccflags-y += -DCONFIG_NSS_CRYPTO_FORCE_UNCACHE=1
+ccflags-y += -DNSS_CRYPTO_DEBUG_LEVEL=2
+ccflags-y += -Werror
+ccflags-y += -DNSS_CRYPTO_BUILD_ID=\"'Build_ID - $(shell date +'%m/%d/%y, %H:%M:%S')'\"
+
+obj-m += $(NSS_CRYPTO_MOD_NAME).o
+$(NSS_CRYPTO_MOD_NAME)-objs = nss_crypto_if.o
+$(NSS_CRYPTO_MOD_NAME)-objs += nss_crypto_ctrl.o
+$(NSS_CRYPTO_MOD_NAME)-objs += nss_crypto_debugfs.o
+
+ifneq ($(findstring 3.4, $(KERNELVERSION)),)
+$(NSS_CRYPTO_MOD_NAME)-objs += nss_crypto_platform.o
+else
+$(NSS_CRYPTO_MOD_NAME)-objs += nss_crypto_dtsi.o
+endif
+
+obj ?= .
+ccflags-y += -I$(obj)/include -I$(obj)/
diff --git a/drivers/crypto/nss/nss_crypto_ctrl.c b/drivers/crypto/nss/nss_crypto_ctrl.c
new file mode 100644
index 0000000..10b8684
--- /dev/null
+++ b/drivers/crypto/nss/nss_crypto_ctrl.c
@@ -0,0 +1,1282 @@
+/* Copyright (c) 2013, 2015-2017, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+ * AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT
+ * INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+ * LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
+ * OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+ * PERFORMANCE OF THIS SOFTWARE.
+ *
+ *
+ */
+
+#include <nss_crypto_hlos.h>
+#include <nss_api_if.h>
+#include <nss_crypto.h>
+#include <nss_crypto_if.h>
+#include <nss_crypto_hw.h>
+#include <nss_crypto_ctrl.h>
+#include <nss_crypto_dbg.h>
+
+struct nss_crypto_ctrl gbl_crypto_ctrl;
+
+extern struct nss_crypto_drv_ctx gbl_ctx;
+
+static int free_timeout = 10;
+module_param(free_timeout, int, 0644);
+MODULE_PARM_DESC(free_timeout, "Max Timeout for Crypto session deallocation in seconds");
+
+#define NSS_CRYPTO_SIZE_KB(x) ((x) >> 10)
+
+/*
+ * Standard initialization vector for SHA-1, source: FIPS 180-2
+ */
+static const uint32_t fips_sha1_iv[NSS_CRYPTO_AUTH_IV_REGS] = {
+	0x67452301, 0xEFCDAB89, 0x98BADCFE, 0x10325476, 0xC3D2E1F0
+};
+
+/*
+ * Standard initialization vector for SHA-256, source: FIPS 180-2
+ */
+static uint32_t fips_sha256_iv[NSS_CRYPTO_AUTH_IV_REGS] = {
+	0x6A09E667, 0xBB67AE85, 0x3C6EF372, 0xA54FF53A,
+	0x510E527F, 0x9B05688C, 0x1F83D9AB, 0x5BE0CD19
+};
+
+/*
+ * NULL IV
+ */
+static const uint32_t null_iv[NSS_CRYPTO_AUTH_IV_REGS] = {0};
+
+/*
+ * NULL keys
+ */
+static const uint8_t null_ckey[NSS_CRYPTO_CKEY_SZ] = {0};
+static const uint8_t null_akey[NSS_CRYPTO_AKEY_SZ] = {0};
+
+/*
+ * nss_crypto_mem_realloc
+ * 	Allocate the memory to accommodate present & previous instances.
+ * 	If instance is not present earlier then the memory will be allocated
+ * 	for the same.
+ *
+ * 	NOTE: Older memory will be freed up and this shall not be called
+ * 	from atomic context.
+ */
+void *nss_crypto_mem_realloc(void *src, size_t src_len, size_t dst_len)
+{
+	void *dst = NULL;
+
+	/*
+	 * Allocate the memory to accommodate present & previous
+	 * instances
+	 *
+	 * NOTE: Currently it is assumed that the memory requirements
+	 * can be addressed by contiguos allocations
+	 */
+	dst = kzalloc(dst_len, GFP_KERNEL);
+	if (dst == NULL) {
+		nss_crypto_err("Unable to allocate memory\n");
+		return NULL;
+	}
+
+	/*
+	 * Check if it is first allocation
+	 */
+	if ((src == NULL) || (src_len == 0)) {
+		return dst;
+	}
+
+	/*
+	 * Copy the earlier allocated memory to newly allocated memory
+	 */
+	memcpy(dst, src, src_len);
+
+	/*
+	 * Free_up the earlier allocation
+	 */
+	kfree(src);
+
+	return dst;
+}
+
+/*
+ * nss_crypto_clear_cblk()
+ * 	this updates CMD block mask to indicate valid bits to write in the registers
+ */
+static inline void nss_crypto_update_cblk_mask(struct nss_crypto_bam_cmd *cmd, bool clr)
+{
+	cmd->mask = clr ? 0 : CRYPTO_MASK_ALL;
+}
+
+/*
+ * nss_crypto_write_cblk()
+ * 	load CMD block with data
+ *
+ * it will load
+ * - crypto register offsets
+ * - crypto register values
+ */
+static inline void nss_crypto_write_cblk(struct nss_crypto_bam_cmd *cmd, uint32_t addr, uint32_t value)
+{
+	cmd->addr = CRYPTO_CMD_ADDR(addr);
+	cmd->value = value;
+	cmd->mask = CRYPTO_MASK_ALL;
+}
+
+/*
+ * nss_crypto_read_cblk()
+ * 	read CMD block data
+ */
+static inline uint32_t nss_crypto_read_cblk(struct nss_crypto_bam_cmd *cmd)
+{
+	return (cmd->value & cmd->mask);
+}
+/*
+ * nss_crypto_setup_cmd_config()
+ * 	setup the common command block, 1 per session
+ */
+static void nss_crypto_setup_cmd_config(struct nss_crypto_cmd_config *cfg, uint32_t base_addr, uint16_t pp_num,
+					struct nss_crypto_encr_cfg *encr, struct nss_crypto_auth_cfg *auth)
+{
+	uint32_t *key_ptr, key_val;
+	uint32_t cfg_value, beat;
+	int i;
+
+	/*
+	 * Configuration programming
+	 * - beats
+	 * - interrupts
+	 * - pipe number for the crypto transaction
+	 */
+	beat = CRYPTO_BURST2BEATS(CRYPTO_MAX_BURST);
+
+	cfg_value = 0;
+	cfg_value |= CRYPTO_CONFIG_DOP_INTR; /* operation interrupt */
+	cfg_value |= CRYPTO_CONFIG_DIN_INTR; /* input interrupt */
+	cfg_value |= CRYPTO_CONFIG_DOUT_INTR; /* output interrupt */
+	cfg_value |= CRYPTO_CONFIG_PIPE_SEL(pp_num); /* pipe pair number to use */
+	cfg_value |= CRYPTO_CONFIG_REQ_SIZE(beat); /* BAM DMA maximum beat size */
+
+	nss_crypto_write_cblk(&cfg->config_0, CRYPTO_CONFIG + base_addr, cfg_value);
+	nss_crypto_write_cblk(&cfg->encr_seg_cfg, CRYPTO_ENCR_SEG_CFG + base_addr, encr->cfg);
+	nss_crypto_write_cblk(&cfg->auth_seg_cfg, CRYPTO_AUTH_SEG_CFG + base_addr, auth->cfg);
+
+	nss_crypto_update_cblk_mask(&cfg->encr_seg_cfg, !encr->cfg);
+	nss_crypto_update_cblk_mask(&cfg->auth_seg_cfg, !auth->cfg);
+
+	nss_crypto_write_cblk(&cfg->encr_ctr_msk, CRYPTO_ENCR_CNTR_MASK + base_addr, 0xffffffff);
+
+	/*
+	 * auth IV update
+	 */
+	for (i = 0; i < NSS_CRYPTO_AUTH_IV_REGS; i++) {
+		nss_crypto_write_cblk(&cfg->auth_iv[i], CRYPTO_AUTH_IVn(i) + base_addr, auth->iv[i]);
+		nss_crypto_update_cblk_mask(&cfg->auth_iv[i], !auth->cfg);
+	}
+
+	/*
+	 * cipher key update
+	 */
+	for (i = 0; i < NSS_CRYPTO_CKEY_REGS; i++) {
+		key_ptr = (uint32_t *)&encr->key[i * 4];
+		key_val = cpu_to_be32(*key_ptr);
+
+		nss_crypto_write_cblk(&cfg->keys.encr[i], CRYPTO_ENCR_KEYn(i) + base_addr, key_val);
+	}
+
+	/*
+	 * auth key update
+	 */
+	for (i = 0; i < NSS_CRYPTO_AKEY_REGS; i++) {
+		key_ptr = (uint32_t *)&auth->key[i * 4];
+		key_val = cpu_to_be32(*key_ptr);
+
+		nss_crypto_write_cblk(&cfg->keys.auth[i], CRYPTO_AUTH_KEYn(i) + base_addr, key_val);
+		nss_crypto_update_cblk_mask(&cfg->keys.auth[i], !auth->cfg);
+	}
+
+}
+
+/*
+ * nss_crypto_setup_cmd_request()
+ * 	setup the per request command block
+ */
+static void nss_crypto_setup_cmd_request(struct nss_crypto_cmd_request *req, uint32_t base_addr, uint16_t pp_num)
+{
+	uint32_t cfg_value;
+	uint32_t beat;
+	int i;
+
+	nss_crypto_write_cblk(&req->seg_size, CRYPTO_SEG_SIZE + base_addr, 0);
+	nss_crypto_write_cblk(&req->encr_seg_size, CRYPTO_ENCR_SEG_SIZE + base_addr, 0);
+	nss_crypto_write_cblk(&req->auth_seg_size, CRYPTO_AUTH_SEG_SIZE + base_addr, 0);
+
+	/*
+	 * cipher IV and counter reset
+	 */
+	for (i = 0; i < NSS_CRYPTO_CIPHER_IV_REGS; i++) {
+		nss_crypto_write_cblk(&req->encr_iv[i], CRYPTO_ENCR_CNTRn_IVn(i) + base_addr, 0);
+	}
+
+	/*
+	 * Configuration programming
+	 * - beats
+	 * - interrupts
+	 * - pipe number for the crypto transaction
+	 */
+	beat = CRYPTO_BURST2BEATS(CRYPTO_MAX_BURST);
+
+	cfg_value = 0;
+	cfg_value |= CRYPTO_CONFIG_DOP_INTR; /* operation interrupt */
+	cfg_value |= CRYPTO_CONFIG_DIN_INTR; /* input interrupt */
+	cfg_value |= CRYPTO_CONFIG_DOUT_INTR; /* output interrupt */
+	cfg_value |= CRYPTO_CONFIG_PIPE_SEL(pp_num); /* pipe pair number to use */
+	cfg_value |= CRYPTO_CONFIG_REQ_SIZE(beat); /* BAM DMA maximum beat size */
+	cfg_value |= CRYPTO_CONFIG_LITTLE_ENDIAN; /* switch to little endian mode */
+
+	nss_crypto_write_cblk(&req->config_1, CRYPTO_CONFIG + base_addr, cfg_value);
+
+	/*
+	 * go_proc or crypto trigger programming
+	 */
+	cfg_value = 0;
+	cfg_value |= CRYPTO_GOPROC_SET; /* go proc */
+	cfg_value |= CRYPTO_GOPROC_RESULTS_DUMP; /* generate results dump */
+
+	nss_crypto_write_cblk(&req->go_proc, CRYPTO_GO_PROC + base_addr, cfg_value);
+
+	/*
+	 * unlock cmd using dummy debug register enable
+	 */
+	nss_crypto_write_cblk(&req->unlock, CRYPTO_DEBUG_ENABLE + base_addr, 0x1);
+}
+
+/*
+ * nss_crypto_bam_init()
+ * 	initialize  the BAM pipe; pull it out reset and load its configuration
+ */
+static int nss_crypto_bam_pipe_init(struct nss_crypto_ctrl_eng *ctrl, uint32_t pipe)
+{
+	uint32_t cfg;
+	uint32_t in_pipe;
+
+	/*
+	 * Put and Pull BAM pipe from reset
+	 */
+	iowrite32(0x1, ctrl->bam_base + CRYPTO_BAM_P_RST(pipe));
+	iowrite32(0x0, ctrl->bam_base + CRYPTO_BAM_P_RST(pipe));
+
+	in_pipe = NSS_CRYPTO_INPIPE(pipe);
+
+	/*
+	 * set the following
+	 * - direction IN or OUT
+	 * - BAM mode is system
+	 * - enable the pipe
+	 * - BAM pipe lock group common for IN & OUT
+	 */
+	cfg = 0;
+	cfg |= CRYPTO_BAM_P_CTRL_DIRECTION(pipe);
+	cfg |= CRYPTO_BAM_P_CTRL_SYS_MODE;
+	cfg |= CRYPTO_BAM_P_CTRL_EN;
+	cfg |= CRYPTO_BAM_P_CTRL_LOCK_GROUP(in_pipe);
+
+	iowrite32(cfg, ctrl->bam_base + CRYPTO_BAM_P_CTRL(pipe));
+
+	nss_crypto_dbg("BAM_CTRL = 0x%x, pipe = %d\n", ioread32(ctrl->bam_base + CRYPTO_BAM_P_CTRL(pipe)), pipe);
+
+	return 0;
+}
+
+/*
+ * nss_crypto_desc_alloc()
+ * 	allocate crypto descriptor memory from DDR
+ *
+ * this allocates coherent memory for crypto descriptors, the pipe initialization should
+ * tell the size
+ */
+static void *nss_crypto_desc_alloc(struct device *dev, uint32_t *paddr, uint32_t size)
+{
+	void *ret_addr;
+	uint32_t phy_addr;
+
+	size = ALIGN(size, NSS_CRYPTO_DESC_ALIGN);
+
+	ret_addr = kzalloc(size, GFP_KERNEL | GFP_DMA);
+	if (!ret_addr) {
+		nss_crypto_err("OOM: unable to allocate memory of size(%dKB)\n", NSS_CRYPTO_SIZE_KB(size));
+		return NULL;
+	}
+
+	BUG_ON(((uint32_t)ret_addr % NSS_CRYPTO_DESC_ALIGN));
+
+	phy_addr = dma_map_single(dev, ret_addr, size, DMA_TO_DEVICE);
+	if (!phy_addr) {
+		nss_crypto_err("%p:unable to map Vaddr(%p)\n", dev, ret_addr);
+		goto fail;
+	}
+
+	*paddr = phy_addr;
+	return ret_addr;
+
+fail:
+	kfree(ret_addr);
+	return NULL;
+}
+
+/*
+ * nss_crypto_pipe_init()
+ * 	initialize the crypto pipe
+ *
+ * this will
+ * - configure the BAM pipes
+ * - allocate the descriptors
+ * - program the BAM descriptors with the command blocks (lock/unlock)
+ * - update the BAM registers for the ring locations
+ */
+void nss_crypto_pipe_init(struct nss_crypto_ctrl_eng *eng, uint32_t idx, uint32_t *desc_paddr, struct nss_crypto_desc **desc_vaddr)
+{
+	struct nss_crypto_desc *desc;
+	uint32_t in_pipe, out_pipe;
+	uint32_t in_pipe_sz, out_pipe_sz;
+	uint32_t paddr;
+	int i;
+
+	/*
+	 * Init the Crypto Core
+	 */
+	in_pipe = nss_crypto_idx_to_inpipe(idx);
+	out_pipe = nss_crypto_idx_to_outpipe(idx);
+
+	in_pipe_sz = sizeof(struct nss_crypto_in_trans) * NSS_CRYPTO_MAX_QDEPTH;
+	out_pipe_sz = sizeof(struct nss_crypto_out_trans) * NSS_CRYPTO_MAX_QDEPTH;
+
+	nss_crypto_bam_pipe_init(eng, in_pipe);
+	nss_crypto_bam_pipe_init(eng, out_pipe);
+
+	/*
+	 * Allocate descriptors
+	 */
+	desc = nss_crypto_desc_alloc(eng->dev, &paddr, NSS_CRYPTO_DESC_SZ);
+	if (!desc) {
+		nss_crypto_err("%p:unable to allocate BAM pipe descriptors\n", eng);
+		return;
+	}
+
+	*desc_paddr = paddr;
+	*desc_vaddr = desc;
+
+	/*
+	 * write input BAM ring
+	 */
+	iowrite32(paddr, eng->bam_base + CRYPTO_BAM_P_DESC_FIFO_ADDR(in_pipe));
+	iowrite32(in_pipe_sz, eng->bam_base + CRYPTO_BAM_P_FIFO_SIZES(in_pipe));
+
+	/*
+	 * write output BAM ring
+	 */
+	iowrite32(paddr + in_pipe_sz, eng->bam_base + CRYPTO_BAM_P_DESC_FIFO_ADDR(out_pipe));
+	iowrite32(out_pipe_sz, eng->bam_base + CRYPTO_BAM_P_FIFO_SIZES(out_pipe));
+
+	/*
+	 * this loop pre-fills the pipe rings with the command blocks, the data path will
+	 * no longer need to write the command block locations when sending the packets for
+	 * encryption/decryption. The idea header is to avoid as much as possible the writes
+	 * to the uncached locations.
+	 */
+	for (i = 0; i < NSS_CRYPTO_MAX_QDEPTH; i++) {
+		/*
+		 * program CMD0 (encr configs & auth configs)
+		 */
+		desc->in[i].cmd0_lock.data_len = 0;
+		desc->in[i].cmd0_lock.data_start = 0x0;
+		desc->in[i].cmd0_lock.flags = (CRYPTO_BAM_DESC_CMD | CRYPTO_BAM_DESC_LOCK);
+
+		/*
+		 * program CMD1 (config & go_proc)
+		 */
+		desc->in[i].cmd1.data_len = NSS_CRYPTO_CMD_REQ_SZ;
+		desc->in[i].cmd1.data_start = 0x0;
+		desc->in[i].cmd1.flags = CRYPTO_BAM_DESC_CMD;
+
+		desc->in[i].data.flags = (CRYPTO_BAM_DESC_EOT | CRYPTO_BAM_DESC_NWD);
+
+		/*
+		 * program CMD2 (unlock)
+		 */
+		desc->in[i].cmd2_unlock.data_len = NSS_CRYPTO_CMD_UNLOCK_SZ;
+		desc->in[i].cmd2_unlock.data_start = 0x0;
+		desc->in[i].cmd2_unlock.flags = (CRYPTO_BAM_DESC_CMD | CRYPTO_BAM_DESC_UNLOCK);
+
+		desc->out[i].data.flags = 0;
+
+		/*
+		 * program results dump
+		 */
+		desc->out[i].results.data_len = NSS_CRYPTO_RESULTS_SZ;
+	}
+
+	nss_crypto_info_always("init completed for Pipe Pair[%d]\n", idx);
+	nss_crypto_dbg("total size - %d, qdepth - %d, in_sz - %d, out_sz - %d\n",
+			NSS_CRYPTO_DESC_SZ, NSS_CRYPTO_MAX_QDEPTH,
+			in_pipe_sz, out_pipe_sz);
+
+}
+
+/*
+ * nss_crypto_program_ckeys()
+ * 	this will program cipher key registers with new keys
+ */
+static void nss_crypto_write_ckey_regs(uint8_t *base, uint16_t pp_num, struct nss_crypto_encr_cfg *encr)
+{
+	uint32_t key_val, *key_ptr;
+	int i;
+
+	nss_crypto_info("updating cached cipher keys\n");
+
+	for (i = 0; i < NSS_CRYPTO_CKEY_REGS ; i++) {
+		key_ptr = (uint32_t *)&encr->key[i * 4];
+		key_val = cpu_to_be32(*key_ptr);
+
+		if (!key_val) {
+			break;
+		}
+
+		iowrite32(key_val, CRYPTO_ENCR_PIPEm_KEYn(pp_num, i) + base);
+	}
+}
+
+/*
+ * nss_crypto_program_akeys()
+ * 	this will program authentication key registers with new keys
+ */
+static void nss_crypto_write_akey_regs(uint8_t *base, uint16_t pp_num, struct nss_crypto_auth_cfg *auth)
+{
+	uint32_t key_val, *key_ptr;
+	int i;
+
+	nss_crypto_info("updating cached auth keys\n");
+
+	for (i = 0; i < NSS_CRYPTO_AKEY_REGS; i++) {
+		key_ptr = (uint32_t *)&auth->key[i * 4];
+		key_val = cpu_to_be32(*key_ptr);
+
+		if (!key_val) {
+			break;
+		}
+
+		iowrite32(key_val, CRYPTO_AUTH_PIPEm_KEYn(pp_num, i) + base);
+	}
+}
+
+/*
+ * nss_crypto_validate_cipher()
+ * 	for a given cipher check whether the programming done by CFI is valid
+ *
+ * this is supposed to verify the
+ * - that the algorithm is supported
+ * - that key size is supported
+ */
+static nss_crypto_status_t nss_crypto_validate_cipher(struct nss_crypto_key *cipher, struct nss_crypto_encr_cfg *encr_cfg)
+{
+	encr_cfg->cfg = 0;
+
+	/*
+	 * NONE, always the first check
+	 */
+	if (cipher == NULL) {
+		memcpy(encr_cfg->key, null_ckey, NSS_CRYPTO_CKEY_SZ);
+
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	nss_crypto_info("validating cipher (algo = %d, key_len = %d)\n", cipher->algo, cipher->key_len);
+
+	/*
+	 * AES-128 CTR
+	 */
+	if ((cipher->algo == NSS_CRYPTO_CIPHER_AES_CTR) && (cipher->key_len == NSS_CRYPTO_KEYLEN_AES128)) {
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_KEY_AES128;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_ALG_AES;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_MODE_CTR;
+
+		memcpy(encr_cfg->key, cipher->key, NSS_CRYPTO_KEYLEN_AES128);
+
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	/*
+	 * AES-256 CTR
+	 */
+	if ((cipher->algo == NSS_CRYPTO_CIPHER_AES_CTR) && (cipher->key_len == NSS_CRYPTO_KEYLEN_AES256)) {
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_KEY_AES256;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_ALG_AES;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_MODE_CTR;
+
+		memcpy(encr_cfg->key, cipher->key, NSS_CRYPTO_KEYLEN_AES256);
+
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	/*
+	 * AES-128 CBC
+	 */
+	if ((cipher->algo == NSS_CRYPTO_CIPHER_AES_CBC) && (cipher->key_len == NSS_CRYPTO_KEYLEN_AES128)) {
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_KEY_AES128;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_ALG_AES;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_MODE_CBC;
+
+		memcpy(encr_cfg->key, cipher->key, NSS_CRYPTO_KEYLEN_AES128);
+
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	/*
+	 * AES-256 CBC
+	 */
+	if ((cipher->algo == NSS_CRYPTO_CIPHER_AES_CBC) && (cipher->key_len == NSS_CRYPTO_KEYLEN_AES256)) {
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_KEY_AES256;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_ALG_AES;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_MODE_CBC;
+
+		memcpy(encr_cfg->key, cipher->key, NSS_CRYPTO_KEYLEN_AES256);
+
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	/*
+	 * DES-64 (SINGLE_DES)
+	 */
+	if ((cipher->algo == NSS_CRYPTO_CIPHER_DES) && (cipher->key_len == NSS_CRYPTO_KEYLEN_DES)) {
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_KEY_SINGLE_DES;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_ALG_DES;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_MODE_CBC;
+
+		memcpy(encr_cfg->key, cipher->key, NSS_CRYPTO_KEYLEN_DES);
+
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	/*
+	 * DES-192 (TRIPLE_DES)
+	 */
+	if ((cipher->algo == NSS_CRYPTO_CIPHER_DES) && (cipher->key_len == NSS_CRYPTO_KEYLEN_3DES)) {
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_KEY_TRIPLE_DES;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_ALG_DES;
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_MODE_CBC;
+
+		memcpy(encr_cfg->key, cipher->key, NSS_CRYPTO_KEYLEN_3DES);
+
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	return NSS_CRYPTO_STATUS_ENOSUPP;
+}
+
+/*
+ * nss_crypto_validate_auth()
+ * 	for a given auth validate the programming done by CFI
+ *
+ * this is supposed to verify the
+ * - that the algorithm is supported
+ * - that key size is supported
+ */
+static nss_crypto_status_t nss_crypto_validate_auth(struct nss_crypto_key *auth, struct nss_crypto_auth_cfg *auth_cfg)
+{
+	auth_cfg->iv = NULL;
+	auth_cfg->cfg = 0;
+
+	/*
+	 * NONE, always the first check
+	 */
+	if (auth == NULL) {
+		auth_cfg->iv = (uint32_t *)&null_iv[0];
+
+		memcpy(auth_cfg->key, null_akey, NSS_CRYPTO_AKEY_SZ);
+
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	nss_crypto_info("validating auth (algo = %d, key_len = %d)\n", auth->algo, auth->key_len);
+
+	/*
+	 * SHA1-HMAC
+	 */
+	if ((auth->algo == NSS_CRYPTO_AUTH_SHA1_HMAC) && (auth->key_len == NSS_CRYPTO_KEYLEN_SHA1HMAC)) {
+		auth_cfg->iv = (uint32_t *)&fips_sha1_iv[0];
+
+		auth_cfg->cfg |= CRYPTO_AUTH_SEG_CFG_MODE_HMAC;
+		auth_cfg->cfg |= (CRYPTO_AUTH_SEG_CFG_ALG_SHA | CRYPTO_AUTH_SEG_CFG_SIZE_SHA1);
+		auth_cfg->cfg |= (CRYPTO_AUTH_SEG_CFG_FIRST | CRYPTO_AUTH_SEG_CFG_LAST);
+
+		memcpy(auth_cfg->key, auth->key, NSS_CRYPTO_KEYLEN_SHA1HMAC);
+
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	/*
+	 * SHA256-HMAC
+	 */
+	if ((auth->algo == NSS_CRYPTO_AUTH_SHA256_HMAC) && (auth->key_len == NSS_CRYPTO_KEYLEN_SHA256HMAC)) {
+
+		auth_cfg->iv = (uint32_t *)&fips_sha256_iv[0];
+
+		auth_cfg->cfg |= CRYPTO_AUTH_SEG_CFG_MODE_HMAC;
+		auth_cfg->cfg |= (CRYPTO_AUTH_SEG_CFG_ALG_SHA | CRYPTO_AUTH_SEG_CFG_SIZE_SHA2);
+		auth_cfg->cfg |= (CRYPTO_AUTH_SEG_CFG_FIRST | CRYPTO_AUTH_SEG_CFG_LAST);
+
+		memcpy(auth_cfg->key, auth->key, NSS_CRYPTO_KEYLEN_SHA256HMAC);
+
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	return NSS_CRYPTO_STATUS_ENOSUPP;
+}
+
+/*
+ * nss_crypto_key_update()
+ * 	update the newly arrived keys/algorithm from session alloc
+ *
+ * this will do the following
+ * - pre-fill the command blocks with cipher/auth specific data
+ * - write new keys to the cipher/auth registers
+ *
+ */
+static void nss_crypto_key_update(struct nss_crypto_ctrl_eng *eng, uint32_t idx, struct nss_crypto_encr_cfg *encr_cfg,
+					struct nss_crypto_auth_cfg *auth_cfg)
+{
+	const uint32_t size = sizeof(struct nss_crypto_cmd_block);
+	struct nss_crypto_ctrl_idx *ctrl_idx;
+	struct nss_crypto_cmd_block *cblk;
+	uint16_t pp_num;
+	uint32_t paddr;
+	int i = 0;
+
+	ctrl_idx = &eng->idx_tbl[idx];
+	pp_num = ctrl_idx->idx.pp_num;
+	cblk = ctrl_idx->cblk;
+
+	/*
+	 * if the indexes are within cached range and force uncached is not set,
+	 * then program the registers
+	 */
+	if ((idx < NSS_CRYPTO_MAX_CACHED_IDXS) && !CONFIG_NSS_CRYPTO_FORCE_UNCACHE) {
+		encr_cfg->cfg |= CRYPTO_ENCR_SEG_CFG_PIPE_KEYS;
+		auth_cfg->cfg |= CRYPTO_AUTH_SEG_CFG_PIPE_KEYS;
+
+		nss_crypto_write_ckey_regs(eng->crypto_base, pp_num, encr_cfg);
+		nss_crypto_write_akey_regs(eng->crypto_base, pp_num, auth_cfg);
+	}
+
+	paddr = ctrl_idx->idx.cblk_paddr;
+
+	dma_unmap_single(eng->dev, paddr, size, DMA_FROM_DEVICE);
+
+	/*
+	 * configuration command setup, this is 1 per session
+	 */
+	nss_crypto_setup_cmd_config(&cblk->cfg, eng->cmd_base, pp_num, encr_cfg, auth_cfg);
+
+	/*
+	 * request command setup, these are 'n' per session; where n = MAX_QDEPTH
+	 */
+	for (i = 0; i < NSS_CRYPTO_MAX_QDEPTH; i++) {
+		nss_crypto_setup_cmd_request(&cblk->req[i], eng->cmd_base, pp_num);
+	}
+
+	paddr = dma_map_single(eng->dev, ctrl_idx->cblk, size, DMA_TO_DEVICE);
+
+	BUG_ON(paddr != ctrl_idx->idx.cblk_paddr);
+}
+
+/*
+ * nss_crypto_cblk_update()
+ * 	update the configuration command block using buffer informantion
+ */
+static inline nss_crypto_status_t nss_crypto_cblk_update(struct nss_crypto_ctrl_eng *eng, struct nss_crypto_cmd_block *cblk,
+						struct nss_crypto_params *params)
+{
+	struct nss_crypto_cmd_config *cfg;
+	uint32_t base_addr = eng->cmd_base;
+	uint32_t encr_cfg = 0, auth_cfg = 0;
+	const uint16_t req_mask = (NSS_CRYPTO_REQ_TYPE_DECRYPT | NSS_CRYPTO_REQ_TYPE_ENCRYPT);
+
+	cfg = &cblk->cfg;
+
+	/*
+	 * update the skip values as the assumption is that it remains constant for a session
+	 */
+	nss_crypto_write_cblk(&cfg->encr_seg_start, CRYPTO_ENCR_SEG_START + base_addr, params->cipher_skip);
+	nss_crypto_write_cblk(&cfg->auth_seg_start, CRYPTO_AUTH_SEG_START + base_addr, params->auth_skip);
+
+	/*
+	 * update the segment configuration for encrypt or decrypt type
+	 */
+	encr_cfg = nss_crypto_read_cblk(&cfg->encr_seg_cfg);
+	auth_cfg = nss_crypto_read_cblk(&cfg->auth_seg_cfg);
+
+	switch (params->req_type & req_mask) {
+	case NSS_CRYPTO_REQ_TYPE_ENCRYPT:
+		encr_cfg |= CRYPTO_ENCR_SEG_CFG_ENC;
+		auth_cfg |= CRYPTO_AUTH_SEG_CFG_POS_AFTER;
+		break;
+
+	case NSS_CRYPTO_REQ_TYPE_DECRYPT:
+		encr_cfg &= ~CRYPTO_ENCR_SEG_CFG_ENC;
+		auth_cfg |= CRYPTO_AUTH_SEG_CFG_POS_BEFORE;
+		break;
+
+	default:
+		nss_crypto_err("unknown request type\n");
+		return NSS_CRYPTO_STATUS_EINVAL;
+	}
+
+	nss_crypto_write_cblk(&cfg->encr_seg_cfg, CRYPTO_ENCR_SEG_CFG + base_addr, encr_cfg);
+	nss_crypto_write_cblk(&cfg->auth_seg_cfg, CRYPTO_AUTH_SEG_CFG + base_addr, auth_cfg);
+
+	return NSS_CRYPTO_STATUS_OK;
+}
+
+/*
+ * nss_crypto_update_cipher_info()
+ * 	update the cipher info into the index info table
+ */
+void nss_crypto_update_cipher_info(struct nss_crypto_idx_info *idx, struct nss_crypto_key *cipher)
+{
+	idx->ckey.algo = cipher ? cipher->algo : NSS_CRYPTO_CIPHER_NONE;
+	idx->ckey.key_len = cipher ? cipher->key_len : 0;
+	idx->ckey.key = NULL;
+}
+
+/*
+ * nss_crypto_update_idx_state()
+ *	Updates the session state
+ */
+void nss_crypto_update_idx_state(struct nss_crypto_idx_info *idx, enum nss_crypto_session_state state)
+{
+	idx->state = state;
+}
+
+/*
+ * nss_crypto_update_idx_reqtype()
+ *	update the session crypto request type (encryption/decryption)
+ */
+static nss_crypto_status_t nss_crypto_update_idx_reqtype(struct nss_crypto_idx_info *idx, uint16_t req_type)
+{
+	const uint16_t req_mask = (NSS_CRYPTO_REQ_TYPE_DECRYPT | NSS_CRYPTO_REQ_TYPE_ENCRYPT);
+
+	/*
+	 * check if the call is for resetting the state
+	 */
+	if (req_type == NSS_CRYPTO_REQ_TYPE_NONE) {
+		idx->req_type = req_type;
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	switch (req_type & req_mask) {
+	case NSS_CRYPTO_REQ_TYPE_ENCRYPT:
+	case NSS_CRYPTO_REQ_TYPE_DECRYPT:
+		idx->req_type = req_type;
+		break;
+
+	default:
+		nss_crypto_err("unknown request type 0x%x\n", req_type);
+		return NSS_CRYPTO_STATUS_EINVAL;
+	}
+	return NSS_CRYPTO_STATUS_OK;
+}
+
+/*
+ * nss_crypto_update_auth_info()
+ * 	update the auth info into the index info table
+ */
+void nss_crypto_update_auth_info(struct nss_crypto_idx_info *idx, struct nss_crypto_key *auth)
+{
+	idx->akey.algo = auth ? auth->algo : NSS_CRYPTO_AUTH_NONE;
+	idx->akey.key_len = auth ? auth->key_len : 0;
+	idx->akey.key = NULL;
+}
+
+/*
+ * nss_crypto_chk_idx_isfree()
+ *	get the session state
+ */
+bool nss_crypto_chk_idx_isfree(struct nss_crypto_idx_info *idx)
+{
+	bool session_state = false;
+
+	if (idx->state != NSS_CRYPTO_SESSION_STATE_ACTIVE) {
+		session_state = true;
+	}
+
+	return session_state;
+}
+
+/*
+ * nss_crypto_wq_function()
+ *	delayed worker to delete session
+ */
+static void nss_crypto_wq_function(struct work_struct *work)
+{
+	struct delayed_work *dwork = to_delayed_work(work);
+	struct nss_crypto_work *cw = container_of(dwork, struct nss_crypto_work, work);
+	uint32_t session_idx = cw->session_idx;
+	nss_crypto_status_t status;
+
+	status = nss_crypto_send_session_update(session_idx, NSS_CRYPTO_SESSION_STATE_FREE, NSS_CRYPTO_CIPHER_NULL);
+	if (status != NSS_CRYPTO_STATUS_OK) {
+		nss_crypto_info("failed to delete session in delayed worker, reschedule the work\n");
+		schedule_delayed_work(&cw->work, msecs_to_jiffies(free_timeout * MSEC_PER_SEC));
+		return;
+	}
+
+	/*
+	 * free the work
+	 */
+	kfree(cw);
+}
+
+/*
+ * nss_crypto_session_update()
+ * 	update allocated crypto session parameters
+ */
+nss_crypto_status_t nss_crypto_session_update(nss_crypto_handle_t crypto, uint32_t session_idx, struct nss_crypto_params *params)
+{
+	const uint32_t size = sizeof(struct nss_crypto_cmd_block);
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_ctrl_eng *e_ctrl = &ctrl->eng[0];
+	nss_crypto_status_t status = NSS_CRYPTO_STATUS_OK;
+	struct nss_crypto_ctrl_idx *ctrl_idx;
+	uint32_t paddr;
+	int i = 0;
+
+	/*
+	 * check if session is a valid active session
+	 */
+	if (!test_bit(session_idx, ctrl->idx_bitmap)) {
+		nss_crypto_err("invalid session index\n");
+		return NSS_CRYPTO_STATUS_FAIL;
+	}
+
+	/*
+	 * Check if the common command block parameters are already set for
+	 * this session
+	 */
+	if (test_bit(session_idx, ctrl->idx_state_bitmap)) {
+		nss_crypto_dbg("Duplicate session update request\n");
+		return NSS_CRYPTO_STATUS_OK;
+	}
+
+	rmb();
+	set_bit(session_idx, ctrl->idx_state_bitmap);
+
+	/*
+	 * Update whether this SA index is used for encryption or decryption
+	 * TODO: Need to evaluate this for the case of pure authentication
+	 */
+	status = nss_crypto_update_idx_reqtype(&ctrl->idx_info[session_idx], params->req_type);
+	if (status != NSS_CRYPTO_STATUS_OK) {
+		nss_crypto_err("invalid parameters\n");
+		return NSS_CRYPTO_STATUS_EINVAL;
+	}
+
+	for (i = 0; i < ctrl->num_eng; i++, e_ctrl++) {
+		ctrl_idx = &e_ctrl->idx_tbl[session_idx];
+		paddr = ctrl_idx->idx.cblk_paddr;
+
+		/*
+		 * Update session specific config data
+		 */
+		dma_unmap_single(e_ctrl->dev, paddr, size, DMA_FROM_DEVICE);
+
+		status = nss_crypto_cblk_update(e_ctrl, ctrl_idx->cblk, params);
+		if (status != NSS_CRYPTO_STATUS_OK) {
+			nss_crypto_err("invalid parameters\n");
+			return NSS_CRYPTO_STATUS_EINVAL;
+		}
+
+		paddr = dma_map_single(e_ctrl->dev, ctrl_idx->cblk, size, DMA_TO_DEVICE);
+
+		BUG_ON(paddr != ctrl_idx->idx.cblk_paddr);
+	}
+	return NSS_CRYPTO_STATUS_OK;
+}
+EXPORT_SYMBOL(nss_crypto_session_update);
+
+/*
+ * nss_crypto_session_alloc_nokey()
+ * 	allocate a new crypto session for operation
+ */
+nss_crypto_status_t nss_crypto_session_alloc_nokey(nss_crypto_handle_t crypto, struct nss_crypto_key *cipher, struct nss_crypto_key *auth,
+						uint32_t *session_idx)
+{
+	return NSS_CRYPTO_STATUS_OK;
+}
+EXPORT_SYMBOL(nss_crypto_session_alloc_nokey);
+
+/*
+ * nss_crypto_session_alloc()
+ * 	allocate a new crypto session for operation
+ */
+nss_crypto_status_t nss_crypto_session_alloc(nss_crypto_handle_t crypto, struct nss_crypto_key *cipher, struct nss_crypto_key *auth,
+						uint32_t *session_idx)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_ctrl_stats *cstats = &ctrl->ctrl_stats;
+	struct nss_crypto_encr_cfg encr_cfg;
+	struct nss_crypto_auth_cfg auth_cfg;
+	enum nss_crypto_cipher cipher_algo;
+	nss_crypto_status_t status;
+	uint32_t idx;
+	int i;
+
+	memset(&encr_cfg, 0, sizeof(struct nss_crypto_encr_cfg));
+	memset(&auth_cfg, 0, sizeof(struct nss_crypto_auth_cfg));
+
+	BUG_ON(in_atomic());
+
+	/*
+	 * validate cipher
+	 */
+	status = nss_crypto_validate_cipher(cipher, &encr_cfg);
+	if (status != NSS_CRYPTO_STATUS_OK) {
+		return status;
+	}
+
+	/*
+	 * validate authentication
+	 */
+	status = nss_crypto_validate_auth(auth, &auth_cfg);
+	if (status != NSS_CRYPTO_STATUS_OK) {
+		return status;
+	}
+
+	spin_lock_bh(&ctrl->lock); /* index lock*/
+
+	if (ctrl->num_idxs == NSS_CRYPTO_MAX_IDXS) {
+		spin_unlock_bh(&ctrl->lock); /* index lock*/
+		return NSS_CRYPTO_STATUS_ENOMEM;
+	}
+
+	/*
+	 * search a free index and allocate it
+	 */
+	idx = find_first_zero_bit(ctrl->idx_bitmap, NSS_CRYPTO_MAX_IDXS);
+
+	ctrl->num_idxs++;
+	set_bit(idx, ctrl->idx_bitmap);
+	clear_bit(idx, ctrl->idx_state_bitmap);
+
+	nss_crypto_update_cipher_info(&ctrl->idx_info[idx], cipher);
+	nss_crypto_update_auth_info(&ctrl->idx_info[idx], auth);
+	nss_crypto_update_idx_state(&ctrl->idx_info[idx], NSS_CRYPTO_SESSION_STATE_ACTIVE);
+
+	/*
+	 * program keys for all the engines for the given pipe pair (index)
+	 */
+	for (i = 0; i < ctrl->num_eng; i++) {
+		nss_crypto_key_update(&ctrl->eng[i], idx, &encr_cfg, &auth_cfg);
+	}
+
+	cipher_algo = cipher ? cipher->algo : NSS_CRYPTO_CIPHER_NULL;
+	spin_unlock_bh(&ctrl->lock); /* index unlock*/
+
+	atomic_inc(&cstats->session_alloc);
+
+	/*
+	 * check if the perf level is nominal; only set it to
+	 * turbo when nominal
+	 */
+	if (atomic_read(&ctrl->perf_level) == NSS_PM_PERF_LEVEL_NOMINAL) {
+		nss_pm_set_perf_level(gbl_ctx.pm_hdl, NSS_PM_PERF_LEVEL_TURBO);
+		if (!wait_for_completion_timeout(&ctrl->perf_complete, NSS_CRYPTO_PERF_LEVEL_TIMEO_TICKS)) {
+			goto fail;
+		}
+	}
+
+	/*
+	 * If the message sending fails, return error
+	 */
+	status = nss_crypto_send_session_update(idx, NSS_CRYPTO_SESSION_STATE_ACTIVE, cipher_algo);
+	if (unlikely(status != NSS_CRYPTO_STATUS_OK)) {
+		goto fail;
+	}
+
+	*session_idx = idx;
+
+	nss_crypto_info("new index - %d (used - %d, max - %d)\n",idx, ctrl->num_idxs, NSS_CRYPTO_MAX_IDXS);
+	nss_crypto_dump_bitmap(ctrl->idx_bitmap, NSS_CRYPTO_MAX_IDXS);
+
+	return NSS_CRYPTO_STATUS_OK;
+
+fail:
+	nss_crypto_dbg("session id[%u] alloc fail\n", idx);
+	atomic_inc(&cstats->session_alloc_fail);
+	nss_crypto_idx_free(idx);
+
+	return NSS_CRYPTO_STATUS_FAIL;
+}
+EXPORT_SYMBOL(nss_crypto_session_alloc);
+
+/*
+ * nss_crypto_session_free()
+ * 	free the crypto session, that was previously allocated
+ */
+nss_crypto_status_t nss_crypto_session_free(nss_crypto_handle_t crypto, uint32_t session_idx)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_work *cw;
+	uint32_t idx_mask;
+
+	idx_mask = (0x1 << session_idx);
+
+	spin_lock_bh(&ctrl->lock); /* index lock */
+
+	if (!ctrl->num_idxs || !test_bit(session_idx, ctrl->idx_bitmap)) {
+		spin_unlock_bh(&ctrl->lock);
+		nss_crypto_err("crypto index(%d) is invalid\n", session_idx);
+		return NSS_CRYPTO_STATUS_EINVAL;
+	}
+
+	spin_unlock_bh(&ctrl->lock); /* index unlock*/
+
+	/*
+	 * schedule deferred timer to delete the sessoin
+	 */
+	cw = kmalloc(sizeof (struct nss_crypto_work), GFP_ATOMIC);
+	if (!cw) {
+		nss_crypto_err("failed to allocate worker for idx-%d", session_idx);
+		return NSS_CRYPTO_STATUS_ENOMEM;
+	}
+	cw->session_idx = session_idx;
+
+	INIT_DELAYED_WORK(&cw->work, nss_crypto_wq_function);
+	schedule_delayed_work(&cw->work, msecs_to_jiffies(free_timeout * MSEC_PER_SEC));
+
+	return NSS_CRYPTO_STATUS_OK;
+}
+EXPORT_SYMBOL(nss_crypto_session_free);
+
+/*
+ * nss_crypto_idx_free()
+ * 	De-allocate all associated resources with session
+ */
+void nss_crypto_idx_free(uint32_t session_idx)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_ctrl_stats *cstats = &ctrl->ctrl_stats;
+	struct nss_crypto_encr_cfg encr_cfg;
+	struct nss_crypto_auth_cfg auth_cfg;
+	int i;
+
+	memset(&encr_cfg, 0, sizeof(struct nss_crypto_encr_cfg));
+	memset(&auth_cfg, 0, sizeof(struct nss_crypto_auth_cfg));
+
+	spin_lock(&ctrl->lock); /* index lock*/
+
+	/*
+	 * NULL configuration
+	 */
+	encr_cfg.cfg = 0;
+	auth_cfg.cfg = 0;
+	auth_cfg.iv = (uint32_t *)&null_iv[0];
+
+	memcpy(encr_cfg.key, null_ckey, NSS_CRYPTO_CKEY_SZ);
+	memcpy(auth_cfg.key, null_akey, NSS_CRYPTO_AKEY_SZ);
+
+	nss_crypto_update_cipher_info(&ctrl->idx_info[session_idx], NULL);
+	nss_crypto_update_auth_info(&ctrl->idx_info[session_idx], NULL);
+	nss_crypto_update_idx_state(&ctrl->idx_info[session_idx], NSS_CRYPTO_SESSION_STATE_FREE);
+	nss_crypto_update_idx_reqtype(&ctrl->idx_info[session_idx], NSS_CRYPTO_REQ_TYPE_NONE);
+
+	/*
+	 * program keys for all the engines for the given pipe pair (index)
+	 */
+	for (i = 0; i < ctrl->num_eng; i++) {
+		nss_crypto_key_update(&ctrl->eng[i], session_idx, &encr_cfg, &auth_cfg);
+	}
+
+	clear_bit(session_idx, ctrl->idx_bitmap);
+	ctrl->num_idxs--;
+
+	spin_unlock(&ctrl->lock); /* index unlock*/
+
+	atomic_inc(&cstats->session_free);
+
+	nss_crypto_info("deallocated index - %d (used - %d, max - %d)\n",session_idx, ctrl->num_idxs, NSS_CRYPTO_MAX_IDXS);
+	nss_crypto_dump_bitmap(ctrl->idx_bitmap, NSS_CRYPTO_MAX_IDXS);
+}
+
+/*
+ * nss_crypto_get_cipher()
+ * 	return the cipher algo with the associated session
+ */
+enum nss_crypto_cipher nss_crypto_get_cipher(uint32_t session_idx)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_idx_info *idx;
+
+	idx = &ctrl->idx_info[session_idx];
+
+	return idx->ckey.algo;
+
+}
+EXPORT_SYMBOL(nss_crypto_get_cipher);
+
+/*
+ * nss_crypto_get_cipher_keylen()
+ * 	return the cipher key length with the associated session
+ */
+uint32_t nss_crypto_get_cipher_keylen(uint32_t session_idx)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_idx_info *idx;
+
+	idx = &ctrl->idx_info[session_idx];
+
+	return idx->ckey.key_len;
+}
+EXPORT_SYMBOL(nss_crypto_get_cipher_keylen);
+
+/*
+ * nss_crypto_get_reqtype()
+ * 	return the transform type of the associated session
+ */
+uint32_t nss_crypto_get_reqtype(uint32_t session_idx)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_idx_info *idx;
+
+	idx = &ctrl->idx_info[session_idx];
+
+	return idx->req_type;
+}
+EXPORT_SYMBOL(nss_crypto_get_reqtype);
+
+/*
+ * nss_crypto_get_auth()
+ * 	return the auth algo with the associated session
+ */
+enum nss_crypto_auth nss_crypto_get_auth(uint32_t session_idx)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_idx_info *idx;
+
+	idx = &ctrl->idx_info[session_idx];
+
+	return idx->akey.algo;
+
+}
+EXPORT_SYMBOL(nss_crypto_get_auth);
+
+/*
+ * nss_crypto_get_auth_keylen()
+ * 	return the auth key length with the associated session
+ */
+uint32_t nss_crypto_get_auth_keylen(uint32_t session_idx)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_idx_info *idx;
+
+	idx = &ctrl->idx_info[session_idx];
+
+	return idx->akey.key_len;
+
+}
+EXPORT_SYMBOL(nss_crypto_get_auth_keylen);
+
+/*
+ * nss_crypto_idx_init()
+ * 	initialize the index table
+ *
+ * note: this also allocates the command blocks and copies the allocated indexes
+ * into a message so that it can be sent to NSS
+ */
+nss_crypto_status_t nss_crypto_idx_init(struct nss_crypto_ctrl_eng *eng, struct nss_crypto_idx msg[])
+{
+	struct nss_crypto_ctrl_idx *ctrl_idx;
+	struct nss_crypto_idx *idx;
+	uint32_t paddr;
+	int i;
+
+	for (i = 0; i < NSS_CRYPTO_MAX_IDXS; i++) {
+		ctrl_idx = &eng->idx_tbl[i];
+		idx = &ctrl_idx->idx;
+		paddr = 0;
+
+		/*
+		 * allocate the command block
+		 */
+		ctrl_idx->cblk = nss_crypto_desc_alloc(eng->dev, &paddr, sizeof(struct nss_crypto_cmd_block));
+		if (!ctrl_idx->cblk) {
+			nss_crypto_err("unable to allocate session table: idx no failed = %d\n", i);
+			return NSS_CRYPTO_STATUS_ENOMEM;
+		}
+
+
+		idx->pp_num = (i % NSS_CRYPTO_BAM_PP);
+		idx->cmd_len = NSS_CRYPTO_CACHE_CMD_SZ;
+
+		/*
+		 * for indexes beyond MAX_CACHED switch to uncached mode
+		 */
+		if ((i >= NSS_CRYPTO_MAX_CACHED_IDXS) || CONFIG_NSS_CRYPTO_FORCE_UNCACHE) {
+			idx->cmd_len = NSS_CRYPTO_UNCACHE_CMD_SZ;
+		}
+
+		idx->cblk_paddr = paddr;
+
+		/*
+		 * finally update the index info into the message
+		 */
+		memcpy(&msg[i], idx, sizeof(struct nss_crypto_idx));
+	}
+
+	return NSS_CRYPTO_STATUS_OK;
+}
+
+/*
+ * nss_crypto_ctrl_stats_init
+ * 	Initialize control stats in crypto control
+ */
+static inline void nss_crypto_ctrl_stats_init(struct nss_crypto_ctrl_stats *stats)
+{
+	atomic_set(&stats->session_alloc, 0);
+	atomic_set(&stats->session_free, 0);
+	atomic_set(&stats->session_alloc_fail, 0);
+}
+
+/*
+ * nss_crypto_ctrl_init()
+ * 	initialize the crypto control
+ */
+void nss_crypto_ctrl_init(void)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+
+	memset(ctrl, 0, sizeof(struct nss_crypto_ctrl));
+
+	spin_lock_init(&ctrl->lock);
+
+	mutex_init(&ctrl->mutex);
+
+	sema_init(&ctrl->sem, 1);
+
+	init_completion(&ctrl->complete);
+	init_completion(&ctrl->perf_complete);
+
+	atomic_set(&ctrl->perf_level, NSS_PM_PERF_LEVEL_IDLE);
+
+	nss_crypto_ctrl_stats_init(&ctrl->ctrl_stats);
+
+	memset(ctrl->idx_bitmap, 0, sizeof(ctrl->idx_bitmap));
+	ctrl->num_eng = 0;
+	ctrl->num_idxs = 0;
+}
diff --git a/drivers/crypto/nss/nss_crypto_ctrl.h b/drivers/crypto/nss/nss_crypto_ctrl.h
new file mode 100644
index 0000000..c4c7783
--- /dev/null
+++ b/drivers/crypto/nss/nss_crypto_ctrl.h
@@ -0,0 +1,269 @@
+/* Copyright (c) 2013, 2015-2016, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+ * AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT
+ * INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+ * LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
+ * OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+ * PERFORMANCE OF THIS SOFTWARE.
+ *
+ *
+ */
+#ifndef __NSS_CRYPTO_CTRL_H
+#define __NSS_CRYPTO_CTRL_H
+
+/**
+ * @brief session free timeout parameters
+ */
+#define NSS_CRYPTO_RESP_TIMEO_TICKS msecs_to_jiffies(3000)	/* Timeout for NSS reponses to Host messages */
+#define NSS_CRYPTO_PERF_LEVEL_TIMEO_TICKS msecs_to_jiffies(10000)	/* Timeout for NSS reponses to Host messages */
+
+#define NSS_CRYPTO_SESSION_BITMAP BITS_TO_LONGS(NSS_CRYPTO_MAX_IDXS)
+
+/**
+ * @brief max key lengths supported for various algorithms
+ */
+enum nss_crypto_keylen_supp {
+	NSS_CRYPTO_KEYLEN_AES128 = 16,		/**< AES-128 bit */
+	NSS_CRYPTO_KEYLEN_AES256 = 32,		/**< AES-256 bit */
+	NSS_CRYPTO_KEYLEN_SHA1HMAC = 20,	/**< SHA1-HMAC */
+	NSS_CRYPTO_KEYLEN_SHA256HMAC = 32,	/**< SHA256-HMAC */
+	NSS_CRYPTO_KEYLEN_DES = 8,		/**< DES-64 bit */
+	NSS_CRYPTO_KEYLEN_3DES = 24,		/**< 3DES-192 bit */
+};
+
+/**
+ * @brief NSS Crypto state
+ */
+enum nss_crypto_state {
+	NSS_CRYPTO_STATE_NOT_READY = 0,      /**< Crypto state is not Ready */
+	NSS_CRYPTO_STATE_READY,              /**< Crypto state is ready */
+	NSS_CRYPTO_STATE_INITIALIZED,        /**< Crypto engines are initialized */
+	NSS_CRYPTO_STATE_MAX
+};
+
+struct nss_crypto_work {
+	struct delayed_work work;	/* Work Structure */
+	uint32_t session_idx;		/* session for which work is scheduled */
+};
+
+struct nss_crypto_encr_cfg {
+	uint32_t cfg;
+	uint8_t key[NSS_CRYPTO_CKEY_SZ];
+};
+
+struct nss_crypto_auth_cfg {
+	uint32_t cfg;
+	uint32_t *iv;
+	uint8_t key[NSS_CRYPTO_AKEY_SZ];
+};
+
+struct nss_crypto_ctrl_idx {
+	struct nss_crypto_idx idx;
+	struct nss_crypto_cmd_block *cblk;
+};
+
+/**
+ * @brief Crypto control specific structure that describes an Engine
+ */
+struct nss_crypto_ctrl_eng {
+	uint32_t cmd_base;	/**< base address for command descriptors (BAM prespective) */
+	uint8_t *crypto_base;	/**< base address for crypto register writes */
+	uint32_t bam_pbase;	/**< physical base address for BAM register writes */
+	uint8_t *bam_base;	/**< base address for BAM regsiter writes */
+	uint32_t bam_ee;	/**< BAM execution enivironment for the crypto engine */
+	struct device *dev;	/**< HLOS device type for the crypto engine */
+
+	struct nss_crypto_desc *hw_desc[NSS_CRYPTO_BAM_PP]; 		/**< H/W descriptors BAM rings, command descriptors */
+	struct nss_crypto_ctrl_idx idx_tbl[NSS_CRYPTO_MAX_IDXS];	/**< index table */
+
+	struct nss_crypto_stats stats;	/**< engine stats */
+	struct dentry *stats_dentry;	/**< debufs entry corresponding to stats directory */
+};
+
+/**
+ * @brief Per index information required for getting information
+ */
+struct nss_crypto_idx_info {
+	struct nss_crypto_key ckey;		/**< cipher key */
+	struct nss_crypto_key akey;		/**< auth key */
+
+	struct nss_crypto_stats stats;		/**< session stats */
+
+	enum nss_crypto_session_state state;	/**< Indicates whether session is active or not */
+
+	struct dentry *stats_dentry;		/**< debufs entry corresponding to stats */
+	struct dentry *cfg_dentry;		/**< debufs entry corresponding to config */
+
+	uint16_t req_type;			/**< transform is for encryption or decryption */
+	uint16_t res;				/**< reserved for padding */
+};
+
+/**
+ * @brief Host maintained control stats
+ */
+struct nss_crypto_ctrl_stats {
+	atomic_t session_alloc;			/**< Sessions allocated */
+	atomic_t session_free;			/**< Sessions freed */
+	atomic_t session_alloc_fail;		/**< Session alloc failures */
+};
+
+/**
+ * @brief NSS crypto clock control
+ */
+struct nss_crypto_clock {
+	struct clk *clk;			/**< Linux clock */
+	uint32_t turbo_freq;			/**< turbo frequency */
+	uint32_t nominal_freq;			/**< nominal frequency */
+};
+
+/**
+ * @brief Main Crypto Control structure, holds information about number of session indexes
+ * number of engines etc.,
+ *
+ * @note currently we support 4 indexes, in future it will allocate more
+ */
+struct nss_crypto_ctrl {
+	unsigned long idx_bitmap[NSS_CRYPTO_SESSION_BITMAP];
+				/**< session allocation bitmap, upto NSS_CRYPTO_MAX_IDXS can be used */
+	unsigned long idx_state_bitmap[NSS_CRYPTO_SESSION_BITMAP];
+				/**< session state bitmap, upto NSS_CRYPTO_MAX_IDXS can be used */
+
+	uint32_t num_idxs;			/**< number of allocated indexes */
+	uint32_t num_eng;			/**< number of available engines */
+
+	atomic_t crypto_state;			/**< crypto devices initialized or not */
+	atomic_t perf_level;			/**< crypto PM perf level */
+
+	spinlock_t lock;			/**< lock */
+	struct mutex mutex;			/**< mutex lock */
+	struct semaphore sem;			/**< semaphore lock */
+
+	struct completion complete;		/**< completion for NSS message */
+	struct completion perf_complete;	/**< completion for NSS message */
+
+	atomic_t complete_timeo;		/**< indicates whether completion has timeout */
+
+	struct delayed_work crypto_work;	/**< crypto_work structure */
+
+	struct nss_crypto_ctrl_eng *eng;	/**< pointer to engines control data information */
+
+	struct nss_crypto_stats total_stats;	/**< crypto total stats */
+	struct nss_crypto_ctrl_stats ctrl_stats;
+						/**< crypto control stats */
+
+	struct dentry *root_dentry;		/**< debufs entry corresponding to qca-nss-crypto directory */
+	struct dentry *stats_dentry;		/**< debufs entry corresponding to stats directory */
+	struct dentry *cfg_dentry;		/**< debufs entry corresponding to config directory */
+
+	struct nss_crypto_clock *clocks;	/**< array of crypto clocks */
+	size_t max_clocks;			/**< maximum no. of available clocks */
+
+	struct nss_crypto_idx_info idx_info[NSS_CRYPTO_MAX_IDXS];
+						/**< per index info */
+};
+
+/**
+ * @brief Driver context structure
+ */
+struct nss_crypto_drv_ctx {
+	struct nss_ctx_instance *drv_hdl;	/**< NSS driver handle */
+	void *pm_hdl;				/**< NSS PM handle */
+};
+
+/*
+ * @brief set crypto state
+ */
+static inline void nss_crypto_set_state(struct nss_crypto_ctrl *ctrl, enum nss_crypto_state state)
+{
+	atomic_set(&ctrl->crypto_state, state);
+}
+
+/*
+ * @brief check crypto state
+ */
+static inline bool nss_crypto_check_state(struct nss_crypto_ctrl *ctrl, enum nss_crypto_state state)
+{
+	return atomic_read(&ctrl->crypto_state) == state;
+}
+
+/*
+ * @brief reset crypto state
+ */
+static inline void nss_crypto_reset_state(struct nss_crypto_ctrl *ctrl)
+{
+	atomic_set(&ctrl->crypto_state, NSS_CRYPTO_STATE_NOT_READY);
+}
+
+/**
+ * @brief Initialize and allocate descriptor memory for a given pipe
+ *
+ * @param eng[IN] Engine context for control operation
+ * @param idx[IN] Pipe pair index number
+ * @param desc_paddr[IN] physical address of H/W descriptor
+ * @param desc_vaddr[IN] virtual address of H/W descriptor
+ *
+ */
+void nss_crypto_pipe_init(struct nss_crypto_ctrl_eng *eng, uint32_t idx, uint32_t *desc_paddr, struct nss_crypto_desc **desc_vaddr);
+
+/**
+ * @brief initiallize the index table per engine
+ *
+ * @param eng[IN] per engine state
+ * @param msg[OUT] message to NSS for each allocated index
+ *
+ * @return status of the call
+ */
+nss_crypto_status_t nss_crypto_idx_init(struct nss_crypto_ctrl_eng *eng, struct nss_crypto_idx *msg);
+
+/**
+ * @brief Initiallize the generic control entities in nss_crypto_ctrl
+ */
+void nss_crypto_ctrl_init(void);
+
+/**
+ * @brief update IV parameters
+ *
+ * @param session_idx[IN] session index
+ * @param state[IN] crypto state (active/free)
+ * @param cipher[IN] cipher algorithm
+ *
+ * @return status of the call
+ */
+nss_crypto_status_t nss_crypto_send_session_update(uint32_t session_idx, enum nss_crypto_session_state state, enum nss_crypto_cipher cipher);
+
+/**
+ * @brief reallocate memory.
+ *
+ * @param src[IN] pointer to src memory
+ * @param src_len[IN]  length of src memory
+ * @param dst_len[IN]  length of new meory required
+ *
+ * @return pointer to new memory allocated
+ */
+void *nss_crypto_mem_realloc(void *src, size_t src_len, size_t dst_len);
+
+/**
+ * @brief deallocate crypto session
+ *
+ * @param session_idx[IN] session index
+ *
+ * @return result of the call
+ */
+void nss_crypto_idx_free(uint32_t session_idx);
+
+/*
+ * @brief checks session's current state
+ *
+ * @param idx_info[IN] pointer to index info structure
+ *
+ * @return true if session is free
+ */
+bool nss_crypto_chk_idx_isfree(struct nss_crypto_idx_info *idx_info);
+#endif /* __NSS_CRYPTO_CTRL_H*/
diff --git a/drivers/crypto/nss/nss_crypto_dbg.h b/drivers/crypto/nss/nss_crypto_dbg.h
new file mode 100644
index 0000000..a5ebd60
--- /dev/null
+++ b/drivers/crypto/nss/nss_crypto_dbg.h
@@ -0,0 +1,108 @@
+/* Copyright (c) 2013, 2016, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+ * AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT
+ * INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+ * LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
+ * OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+ * PERFORMANCE OF THIS SOFTWARE.
+ *
+ *
+ */
+#ifndef __NSS_CRYPTO_DBG_H
+#define __NSS_CRYPTO_DBG_H
+
+#if defined (CONFIG_NSS_CRYPTO_DBG)
+#define nss_crypto_assert(expr)		BUG_ON(!(expr))
+#define nss_crypto_dbg(fmt, arg...)	printk(KERN_DEBUG fmt, ## arg)
+
+/*
+ * nss_crypto_dump_desc()
+ * 	dump the crypto descriptor, use the string to identify the dump
+ */
+static inline void nss_crypto_dump_desc(struct nss_crypto_bam_desc *head, uint32_t num, uint8_t *str)
+{
+	struct nss_crypto_bam_desc *desc;
+	int i;
+
+
+	nss_crypto_dbg("========== %s  ===========\n", str);
+
+	for (i = 0, desc = head; i < num; i++, desc++) {
+		nss_crypto_dbg("desc%d = %p, data_start = 0x%x, data_len = %d, flags = 0x%x\n",
+				i, desc, desc->data_start, desc->data_len, desc->flags);
+	}
+	nss_crypto_dbg("================================\n");
+}
+
+/*
+ * nss_crypto_dump_cblk()
+ * 	dump command block
+ */
+static inline void nss_crypto_dump_cblk(struct nss_crypto_bam_cmd *cmd, uint32_t len, uint8_t *str)
+{
+	int i;
+
+	nss_crypto_dbg("========== %s:CMD Block[%d] ===========\n", str, len);
+	for (i = 0; i < len; i++, cmd++) {
+		nss_crypto_dbg("cmd = %p, reg_addr = 0x%x, reg_val = 0x%x, reg_mask = 0x%x\n",
+				cmd, cmd->addr, cmd->value, cmd->mask);
+	}
+	nss_crypto_dbg("================================\n");
+}
+
+/*
+ * nss_crypto_dump_buf()
+ * 	dump a data buffer till buf_len
+ */
+static inline void nss_crypto_dump_buf(uint8_t *buf, uint32_t buf_len, uint8_t *str)
+{
+	int i = 0;
+
+	nss_crypto_dbg("===== :%s: ===== \n", str);
+
+	for (i = 0; i < buf_len; i++) {
+		nss_crypto_dbg("0x%02x ", buf[i]);
+		if ((i + 1) % 16) {
+			nss_crypto_dbg("\n");
+		}
+	}
+
+	nss_crypto_dbg("\n==============\n");
+}
+
+/*
+ * nss_crypto_dump_bitmap()
+ * 	dump bitmap till the size of session bitmap
+ */
+static inline void nss_crypto_dump_bitmap(unsigned long *addr, uint16_t nbits)
+{
+	uint32_t i = 0;
+	uint32_t loops = BITS_TO_LONGS(nbits);
+
+	nss_crypto_dbg("\n==============\n");
+
+	for(i = 0; i < loops; i++) {
+		nss_crypto_dbg("0x%x ", addr[i]);
+	}
+
+	nss_crypto_dbg("\n==============\n");
+}
+#else
+
+#define nss_crypto_dbg(fmt, arg...)
+#define nss_crypto_assert(expr)
+#define nss_crypto_dump_desc(head, num, str)
+#define nss_crypto_dump_cblk(cmd, len, str)
+#define nss_crypto_dump_buf(buf, len, str)
+#define nss_crypto_dump_bitmap(addr, nbits)
+
+#endif /* !CONFIG_NSS_CRYPTO_DBG */
+
+#endif /* __NSS_CRYPTO_DBG_H */
diff --git a/drivers/crypto/nss/nss_crypto_debugfs.c b/drivers/crypto/nss/nss_crypto_debugfs.c
new file mode 100644
index 0000000..76d2c36
--- /dev/null
+++ b/drivers/crypto/nss/nss_crypto_debugfs.c
@@ -0,0 +1,296 @@
+/* Copyright (c) 2014-2017, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+ * AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT
+ * INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+ * LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
+ * OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+ * PERFORMANCE OF THIS SOFTWARE.
+ *
+ *
+ */
+
+#include <nss_api_if.h>
+#include <nss_crypto_hlos.h>
+#include <nss_crypto_dbg.h>
+#include <nss_crypto_if.h>
+#include <nss_crypto_hw.h>
+#include <nss_crypto_ctrl.h>
+#include <nss_crypto_debugfs.h>
+
+#define NSS_CRYPTO_DEBUGFS_NAME_SZ 64
+
+/*
+ * nss_crypto_debugs_add_stats()
+ * 	Creates debugs entries for common statistics
+ */
+static void nss_crypto_debugfs_add_stats(struct dentry *parent, struct nss_crypto_stats *stats)
+{
+	debugfs_create_u32("queued", S_IRUGO, parent, &stats->queued);
+	debugfs_create_u32("completed", S_IRUGO, parent, &stats->completed);
+	debugfs_create_u32("dropped", S_IRUGO, parent, &stats->dropped);
+}
+
+/*
+ * nss_crypto_debugfs_add_ctrl_stats()
+ * 	Creates debugfs entries for Host maintained control statistics
+ */
+static void nss_crypto_debugfs_add_ctrl_stats(struct dentry *parent, struct nss_crypto_ctrl_stats *stats)
+{
+	debugfs_create_atomic_t("session_alloc", S_IRUGO, parent, &stats->session_alloc);
+	debugfs_create_atomic_t("session_free", S_IRUGO, parent, &stats->session_free);
+	debugfs_create_atomic_t("session_alloc_fail", S_IRUGO, parent, &stats->session_alloc_fail);
+}
+
+/*
+ * nss_crypto_debugfs_init()
+ * 	initiallize the crypto debugfs interface
+ */
+void nss_crypto_debugfs_init(struct nss_crypto_ctrl *ctrl)
+{
+	struct dentry *tstats_dentry, *cstats_dentry;
+
+	ctrl->root_dentry = debugfs_create_dir("qca-nss-crypto", NULL);
+	if (ctrl->root_dentry == NULL) {
+
+		/*
+		 * Non availability of debugfs directory is not a catastrophy
+		 * We can still go ahead with other initialization
+		 */
+		nss_crypto_info_always("Unable to create directory qca-nss-crypto in debugfs\n");
+		return;
+	}
+
+	ctrl->stats_dentry = debugfs_create_dir("stats", ctrl->root_dentry);
+	if (ctrl->stats_dentry == NULL) {
+
+		/*
+		 * Non availability of debugfs directory is not a catastrophy
+		 * We can still go ahead with other initialization
+		 */
+		nss_crypto_info_always("Unable to create directory qca-nss-crypto/stats in debugfs\n");
+		debugfs_remove_recursive(ctrl->root_dentry);
+		return;
+	}
+
+	ctrl->cfg_dentry = debugfs_create_dir("config", ctrl->root_dentry);
+	if (ctrl->cfg_dentry == NULL) {
+
+		/*
+		 * Non availability of debugfs directory is not a catastrophy
+		 * We can still go ahead with other initialization
+		 */
+		nss_crypto_info_always("Unable to create directory qca-nss-crypto/config in debugfs\n");
+		debugfs_remove_recursive(ctrl->root_dentry);
+		return;
+	}
+
+	/*
+	 *  Create a debufs entry corresponding total statistics
+	 */
+	tstats_dentry = debugfs_create_dir("total", ctrl->stats_dentry);
+	if (tstats_dentry == NULL) {
+		nss_crypto_err("Unable to create qca-nss-crypto/stats/total directory in debugfs");
+		return;
+	}
+
+	/*
+	 * create total stats files
+	 */
+	nss_crypto_debugfs_add_stats(tstats_dentry, &ctrl->total_stats);
+
+	/*
+	 * Create a debugfs entry corresponding to host stats
+	 */
+	cstats_dentry = debugfs_create_dir("control", ctrl->stats_dentry);
+	if (cstats_dentry == NULL) {
+		nss_crypto_err("Unable to create qca-nss-crypto/stats/control directory in debugfs");
+		return;
+	}
+
+	/*
+	 * create host stats files
+	 */
+	nss_crypto_debugfs_add_ctrl_stats(cstats_dentry, &ctrl->ctrl_stats);
+}
+
+/*
+ * nss_crypto_debugfs_add_engine()
+ * 	Creates per engine debugfs entries
+ */
+void nss_crypto_debugfs_add_engine(struct nss_crypto_ctrl *ctrl, uint32_t engine_num)
+{
+	char buf[NSS_CRYPTO_DEBUGFS_NAME_SZ];
+	struct nss_crypto_ctrl_eng *e_ctrl = &ctrl->eng[engine_num];
+
+	if (ctrl->root_dentry == NULL) {
+		nss_crypto_err("root directories are not present: unable to add engine data\n");
+		return;
+	}
+
+	memset(buf, 0, NSS_CRYPTO_DEBUGFS_NAME_SZ);
+	scnprintf(buf, sizeof(buf), "engine%d", engine_num);
+
+	e_ctrl->stats_dentry = debugfs_create_dir(buf, ctrl->stats_dentry);
+	if (e_ctrl->stats_dentry == NULL) {
+		nss_crypto_err("Unable to create qca-nss-crypto/stats/%s directory in debugfs", buf);
+		return;
+	}
+
+	/*
+	 * create engine stats files
+	 */
+	nss_crypto_debugfs_add_stats(e_ctrl->stats_dentry, &e_ctrl->stats);
+}
+
+/*
+ * nss_crypto_debugfs_add_session()
+ * 	Creates per session debugfs entries
+ */
+void nss_crypto_debugfs_add_session(struct nss_crypto_ctrl *ctrl, uint32_t idx)
+{
+	char buf[NSS_CRYPTO_DEBUGFS_NAME_SZ];
+	enum nss_crypto_cipher cipher_algo;
+	enum nss_crypto_auth auth_algo;
+	struct dentry *temp_dentry;
+	struct nss_crypto_idx_info *idx_info = &ctrl->idx_info[idx];
+
+	if (ctrl->root_dentry == NULL) {
+		nss_crypto_err("root directories are not present: unable to add session data\n");
+		return;
+	}
+
+	cipher_algo = nss_crypto_get_cipher(idx);
+	auth_algo = nss_crypto_get_auth(idx);
+
+	memset(buf, 0, NSS_CRYPTO_DEBUGFS_NAME_SZ);
+	scnprintf(buf, sizeof(buf), "session%d", idx);
+
+	idx_info->stats_dentry = debugfs_create_dir(buf, ctrl->stats_dentry);
+	if (idx_info->stats_dentry == NULL) {
+		nss_crypto_err("Unable to create qca-nss-crypto/stats/%s directory in debugfs", buf);
+		return;
+	}
+
+	/*
+	 * create sessions stats files
+	 */
+	nss_crypto_debugfs_add_stats(idx_info->stats_dentry, &idx_info->stats);
+
+	/*
+	 * create session cfg info files
+	 */
+	idx_info->cfg_dentry = debugfs_create_dir(buf, ctrl->cfg_dentry);
+	if (idx_info->cfg_dentry == NULL) {
+		nss_crypto_err("Unable to create qca-nss-crypto/config/%s directory in debugfs", buf);
+		return;
+	}
+
+	/*
+	 * populate the cipher information
+	 */
+	temp_dentry = debugfs_create_dir("cipher", idx_info->cfg_dentry);
+	if (temp_dentry == NULL) {
+		nss_crypto_err("Unable to create qca-nss-crypto/config/%s/cipher directory in debugfs", buf);
+		return;
+	}
+
+	/*
+	 * A file whose name represent the session's cipher algorithm
+	 * will be created. Reading the file will return key length
+	 * corresponding to algorithm in bytes
+	 */
+	switch (cipher_algo) {
+	case NSS_CRYPTO_CIPHER_NONE:
+		debugfs_create_u32("NONE", S_IRUGO, temp_dentry, &idx_info->ckey.key_len);
+		break;
+
+	case NSS_CRYPTO_CIPHER_AES_CBC:
+		debugfs_create_u32("AES-CBC", S_IRUGO, temp_dentry, &idx_info->ckey.key_len);
+		break;
+
+	case NSS_CRYPTO_CIPHER_AES_CTR:
+		debugfs_create_u32("AES-CTR", S_IRUGO, temp_dentry, &idx_info->ckey.key_len);
+		break;
+
+	case NSS_CRYPTO_CIPHER_DES:
+		debugfs_create_u32("DES", S_IRUGO, temp_dentry, &idx_info->ckey.key_len);
+		break;
+
+	case NSS_CRYPTO_CIPHER_NULL:
+		debugfs_create_u32("NULL", S_IRUGO, temp_dentry, &idx_info->ckey.key_len);
+		break;
+
+	default:
+		nss_crypto_err("Unknown cipher algorithm:%d\n", cipher_algo);
+		break;
+	}
+
+	/*
+	 * populate the authentication information
+	 */
+	temp_dentry = debugfs_create_dir("auth", idx_info->cfg_dentry);
+	if (temp_dentry == NULL) {
+		nss_crypto_err("Unable to create qca-nss-crypto/config/%s/auth directory in debugfs", buf);
+		return;
+	}
+
+	/*
+	 * A file whose name represent the session's authentication algorithm
+	 * will be created. Reading the file will return key length
+	 * corresponding to algorithm in bytes
+	 */
+	switch (auth_algo) {
+	case NSS_CRYPTO_AUTH_NONE:
+		debugfs_create_u32("NONE", S_IRUGO, temp_dentry, &idx_info->akey.key_len);
+		break;
+
+	case NSS_CRYPTO_AUTH_SHA1_HMAC:
+		debugfs_create_u32("SHA1", S_IRUGO, temp_dentry, &idx_info->akey.key_len);
+		break;
+
+	case NSS_CRYPTO_AUTH_SHA256_HMAC:
+		debugfs_create_u32("SHA256", S_IRUGO, temp_dentry, &idx_info->akey.key_len);
+		break;
+
+	case NSS_CRYPTO_AUTH_NULL:
+		debugfs_create_u32("NULL", S_IRUGO, temp_dentry, &idx_info->akey.key_len);
+		break;
+
+	default:
+		nss_crypto_err("Unknown authentication alogrithm :%d\n", auth_algo);
+		break;
+	}
+
+}
+
+/*
+ * nss_crypto_debugfs_del_delete()
+ * 	deletes per session debugfs entries
+ */
+void nss_crypto_debugfs_del_session(struct nss_crypto_ctrl *ctrl, uint32_t idx)
+{
+	struct nss_crypto_idx_info *idx_info = &ctrl->idx_info[idx];
+
+	if (idx_info->stats_dentry == NULL)  {
+		nss_crypto_err("Unable to find the directory\n");
+		return;
+	}
+
+	debugfs_remove_recursive(idx_info->stats_dentry);
+	idx_info->stats_dentry = NULL;
+
+	if (idx_info->cfg_dentry == NULL)  {
+		nss_crypto_err("Unable to find the file\n");
+		return;
+	}
+
+	debugfs_remove_recursive(idx_info->cfg_dentry);
+	idx_info->cfg_dentry = NULL;
+}
diff --git a/drivers/crypto/nss/nss_crypto_debugfs.h b/drivers/crypto/nss/nss_crypto_debugfs.h
new file mode 100644
index 0000000..265267d
--- /dev/null
+++ b/drivers/crypto/nss/nss_crypto_debugfs.h
@@ -0,0 +1,49 @@
+/* Copyright (c) 2014, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+ * AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT
+ * INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+ * LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
+ * OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+ * PERFORMANCE OF THIS SOFTWARE.
+ *
+ *
+ */
+
+/**
+ * @brief initiallize the crypto debugfs interface
+ *
+ * @param ctrl[IN] pointer to crypto control structure
+ */
+void nss_crypto_debugfs_init(struct nss_crypto_ctrl *ctrl);
+
+/**
+ * @brief creates per engine debugfs entries
+ *
+ * @param ctrl[IN] pointer to crypto control structure
+ * @param engine_id[IN] engine id
+ */
+void nss_crypto_debugfs_add_engine(struct nss_crypto_ctrl *ctrl, uint32_t engine_num);
+
+/**
+ * @brief creates per session debugfs entries
+ *
+ * @param ctrl[IN] pointer to crypto control structure
+ * @param session_idx[IN] session index.
+ */
+void nss_crypto_debugfs_add_session(struct nss_crypto_ctrl *ctrl, uint32_t idx);
+
+/**
+ * @brief deletes per session debugfs entries
+ *
+ * @param ctrl[IN] pointer to crypto control structure
+ * @param session_idx[IN] session index.
+ */
+void nss_crypto_debugfs_del_session(struct nss_crypto_ctrl *ctrl, uint32_t idx);
+
diff --git a/drivers/crypto/nss/nss_crypto_dtsi.c b/drivers/crypto/nss/nss_crypto_dtsi.c
new file mode 100644
index 0000000..811a2f6
--- /dev/null
+++ b/drivers/crypto/nss/nss_crypto_dtsi.c
@@ -0,0 +1,486 @@
+/* Copyright (c) 2013, 2015-2017 The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+ * AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT
+ * INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+ * LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
+ * OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+ * PERFORMANCE OF THIS SOFTWARE.
+ *
+ *
+ */
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/device.h>
+#include <linux/memory.h>
+#include <linux/io.h>
+#include <linux/clk.h>
+#include <linux/uaccess.h>
+#include <linux/dma-mapping.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/of_net.h>
+#include <linux/of_irq.h>
+#include <linux/of_platform.h>
+#include <linux/of_address.h>
+#include <linux/reset.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/vmalloc.h>
+#include <nss_crypto_hlos.h>
+#include <nss_api_if.h>
+#include <nss_crypto.h>
+#include <nss_crypto_if.h>
+#include <nss_crypto_hw.h>
+#include <nss_crypto_ctrl.h>
+#include <nss_crypto_dbg.h>
+#include <nss_crypto_debugfs.h>
+
+/* Poll time in ms */
+#define CRYPTO_DELAYED_INIT_TIME	100
+
+/*
+ * Crypto Clock Freq Table
+ * +------------------+-------------+--------------+
+ * | Clock            | Nominal     |  Turbo       |
+ * +------------------+-------------+--------------+
+ * | NSS_CE5_CORE_CLK | 150 Mhz     |  213.2 Mhz   |
+ * +------------------+-------------+--------------+
+ * | NSS_CE5_AHB_CLK  | 160 Mhz     |  213.2 Mhz   |
+ * +------------------+-------------+--------------+
+ * | NSS_CE5_AXI_CLK  | 160 Mhz     |  213.2 Mhz   |
+ * +------------------+-------------+--------------+
+ *
+ */
+#define NSS_CRYPTO_CLOCK_TURBO 213200000	/* Turbo Freq for Core, AXI and AHB */
+#define NSS_CRYPTO_CLOCK_CORE_NOMINAL 150000000	/* Nominal freq for Core Clock */
+#define NSS_CRYPTO_CLOCK_AUX_NOMINAL 160000000	/* Nominal freq for AXI and AHB */
+
+/*
+ * Crypto resource index in device tree
+ */
+enum nss_crypto_dt_res {
+	NSS_CRYPTO_DT_CRYPTO_RES = 0,
+	NSS_CRYPTO_DT_BAM_RES = 1,
+	NSS_CRYPTO_DT_MAX_RES
+};
+
+extern struct nss_crypto_ctrl gbl_crypto_ctrl;
+extern struct nss_ctx_instance *nss_drv_hdl;
+
+static int eng_count;
+
+int nss_crypto_engine_init(uint32_t eng_count);
+void nss_crypto_init(void);
+void nss_crypto_user_attach_all(struct nss_crypto_ctrl *ctrl);
+
+/*
+ * nss_crypto_bam_init()
+ *	initialize the BAM for the given engine
+ */
+static void nss_crypto_bam_init(uint8_t *bam_iobase)
+{
+	uint32_t cfg_bits;
+	uint32_t ctrl_reg;
+
+	ctrl_reg = ioread32(bam_iobase + CRYPTO_BAM_CTRL);
+
+	ctrl_reg |= CRYPTO_BAM_CTRL_SW_RST;
+	iowrite32(ctrl_reg, bam_iobase + CRYPTO_BAM_CTRL);
+
+	ctrl_reg &= ~CRYPTO_BAM_CTRL_SW_RST;
+	iowrite32(ctrl_reg, bam_iobase + CRYPTO_BAM_CTRL);
+
+	ctrl_reg |= CRYPTO_BAM_CTRL_BAM_EN;
+	iowrite32(ctrl_reg, bam_iobase + CRYPTO_BAM_CTRL);
+
+	iowrite32(CRYPTO_BAM_DESC_CNT_TRSHLD_VAL, bam_iobase +  CRYPTO_BAM_DESC_CNT_TRSHLD);
+
+	/* disabling this is recommended from H/W specification*/
+	cfg_bits = ~((uint32_t)CRYPTO_BAM_CNFG_BITS_BAM_FULL_PIPE);
+	iowrite32(cfg_bits, bam_iobase + CRYPTO_BAM_CNFG_BITS);
+}
+
+/*
+ * nss_crypto_pm_event_cb()
+ * 	Crypto PM event callback
+ */
+bool nss_crypto_pm_event_cb(void *app_data, bool turbo, bool auto_scale)
+{
+	struct nss_crypto_ctrl *ctrl = (struct nss_crypto_ctrl *)app_data;
+	struct nss_crypto_clock *clock = ctrl->clocks;
+	bool session;
+	int count;
+
+	BUG_ON(!clock);
+	count = ctrl->max_clocks;
+
+	spin_lock_bh(&ctrl->lock); /* index lock*/
+	session = !bitmap_empty(ctrl->idx_bitmap, NSS_CRYPTO_MAX_IDXS);
+	spin_unlock_bh(&ctrl->lock); /* index unlock */
+
+	/*
+	 * if, there is no-sessions & the system is not in
+	 * turbo then crypto doesn't need to scale. Once,
+	 * the system has moved to turbo then we cannot
+	 * roll back
+	 */
+	if (!session) {
+		return false;
+	} else if (session && !turbo) {
+		return false;
+	}
+
+	/*
+	 * notify NSS to switch NSS subsystem to turbo
+	 */
+	for (; count--; clock++) {
+		if (clk_set_rate(clock->clk, clock->turbo_freq)) {
+			nss_crypto_err("Error in setting clock(%d) to %d\n", count, clock->turbo_freq);
+			continue;
+		}
+	}
+
+	/*
+	 * we will remove the callback at this point to ensure that crypto doesn't
+	 * scale down anymore
+	 */
+	nss_crypto_pm_notify_unregister();
+
+	atomic_set(&ctrl->perf_level, NSS_PM_PERF_LEVEL_TURBO);
+	complete(&ctrl->perf_complete);
+
+	return true;
+}
+
+/*
+ * nss_crypto_clock_init()
+ * 	initialize crypto clock
+ */
+static void nss_crypto_clock_init(struct platform_device *pdev, struct device_node *np)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_clock *clock;
+	const char *clk_string;
+	size_t clock_array_sz;
+	int count, i;
+
+	count = of_property_count_strings(np, "clock-names");
+	if (count < 0) {
+		nss_crypto_info("crypto clock instance not found\n");
+		return;
+	}
+
+	clock_array_sz = sizeof(struct nss_crypto_clock) * count;
+
+	clock = kzalloc(clock_array_sz, GFP_KERNEL);
+	if (!clock) {
+		nss_crypto_err("Error in allocating clock array (size:%d)\n", clock_array_sz);
+		return;
+	}
+
+	ctrl->max_clocks = count;
+	ctrl->clocks = clock;
+
+	for (i = 0; i < count; i++, clock++) {
+		/*
+		 * parse clock names from DTSI
+		 */
+		of_property_read_string_index(np, "clock-names", i, &clk_string);
+
+		clock->clk = devm_clk_get(&pdev->dev, clk_string);
+		BUG_ON(!clock->clk);
+
+		nss_crypto_info("clock mapping clock(%d) --> %s\n", i, clk_string);
+
+		clk_prepare_enable(clock->clk);
+
+		clock->nominal_freq = NSS_CRYPTO_CLOCK_AUX_NOMINAL;
+		clock->turbo_freq = NSS_CRYPTO_CLOCK_TURBO;
+
+		/*
+		 * switch the core clock for nominal frequency
+		 */
+		if (unlikely(!strncmp(clk_string, "ce5_core", sizeof("ce5_core")))) {
+			clock->nominal_freq = NSS_CRYPTO_CLOCK_CORE_NOMINAL;
+		}
+	}
+
+	atomic_set(&ctrl->perf_level, NSS_PM_PERF_LEVEL_NOMINAL);
+	nss_crypto_pm_notify_register(nss_crypto_pm_event_cb, ctrl);
+}
+
+/*
+ * nss_crypto_probe()
+ *	probe routine called per engine from MACH-MSM
+ */
+static int nss_crypto_probe(struct platform_device *pdev)
+{
+	struct reset_control *rst_ctl __attribute__((unused));
+	struct nss_crypto_ctrl_eng *eng_ptr;
+	struct nss_crypto_ctrl_eng *e_ctrl;
+	struct resource crypto_res = {0};
+	struct resource bam_res = {0};
+	struct device_node *np;
+	uint32_t bam_ee = 0;
+	size_t old_sz;
+	size_t new_sz;
+
+	if (nss_crypto_check_state(&gbl_crypto_ctrl, NSS_CRYPTO_STATE_NOT_READY)) {
+		nss_crypto_info_always("exiting probe due to previous error\n");
+		return -ENOMEM;
+	}
+
+	nss_crypto_info_always("probing engine - %d\n", eng_count);
+	nss_crypto_assert(eng_count < NSS_CRYPTO_MAX_ENGINES);
+
+	if (!pdev->dev.of_node) {
+		nss_crypto_info_always("%sError Accessing dev node\n", __func__);
+		return -ENODEV;
+	}
+
+	/* crypto engine resources */
+	nss_crypto_info_always("Device Tree node found\n");
+	np = of_node_get(pdev->dev.of_node);
+
+	/*
+	 * initialize crypto clock
+	 */
+	nss_crypto_clock_init(pdev, np);
+
+#if defined CONFIG_RESET_CONTROLLER
+	/*
+	 * Reset Crypto AHB, when first crypto engine is probed
+	 */
+	rst_ctl = devm_reset_control_get(&pdev->dev, "rst_ahb");
+	if (!IS_ERR(rst_ctl) && (reset_control_deassert(rst_ctl) > 0)) {
+		nss_crypto_info_always("Crypto AHB pulled out-of-reset\n");
+	}
+
+	/*
+	 * Reset the Crypto Engine
+	 */
+	rst_ctl = devm_reset_control_get(&pdev->dev, "rst_eng");
+	if (!IS_ERR(rst_ctl) && (reset_control_deassert(rst_ctl) > 0)) {
+		nss_crypto_info_always("Crypto Engine (%d) pulled out-of-reset\n", eng_count);
+	}
+#endif
+
+	/*
+	 * Crypto Registers
+	 */
+	if (of_address_to_resource(np, NSS_CRYPTO_DT_CRYPTO_RES, &crypto_res) != 0) {
+		nss_crypto_err("Error in retreiving crypto_base\n");
+		return -EINVAL;
+	}
+
+	/*
+	 * BAM Registers
+	 */
+	if (of_address_to_resource(np, NSS_CRYPTO_DT_BAM_RES, &bam_res) != 0) {
+		nss_crypto_err("Error in retreiving bam_base\n");
+		return -EINVAL;
+	}
+
+	/*
+	 * BAM Execution Environment
+	 */
+	if (of_property_read_u32(np, "qcom,ee", &bam_ee)) {
+		nss_crypto_err("Error retreiving crypto EE for engine(%d)\n", eng_count);
+		return -EINVAL;
+	}
+
+	eng_ptr = gbl_crypto_ctrl.eng;
+	old_sz = (gbl_crypto_ctrl.num_eng * sizeof(struct nss_crypto_ctrl_eng));
+	new_sz = old_sz + sizeof(struct nss_crypto_ctrl_eng);
+
+	eng_ptr = nss_crypto_mem_realloc(eng_ptr, old_sz, new_sz);
+	if (!eng_ptr) {
+		return -ENOMEM;
+	}
+
+	gbl_crypto_ctrl.eng = eng_ptr;
+
+	e_ctrl = &gbl_crypto_ctrl.eng[eng_count];
+	e_ctrl->dev = &pdev->dev;
+
+	e_ctrl->cmd_base = crypto_res.start;
+	e_ctrl->crypto_base = ioremap_nocache(e_ctrl->cmd_base, resource_size(&crypto_res));
+	nss_crypto_assert(e_ctrl->crypto_base);
+
+	e_ctrl->bam_pbase = bam_res.start;
+	e_ctrl->bam_base = ioremap_nocache(e_ctrl->bam_pbase, resource_size(&bam_res));
+	nss_crypto_assert(e_ctrl->bam_base);
+
+	e_ctrl->bam_ee = bam_ee;
+
+	/*
+	 * Link address of engine ctrl
+	 */
+	platform_set_drvdata(pdev, e_ctrl);
+
+	/*
+	 * intialize the BAM and the engine
+	 */
+	nss_crypto_bam_init(e_ctrl->bam_base);
+
+	if (nss_crypto_engine_init(eng_count) != NSS_CRYPTO_STATUS_OK) {
+		nss_crypto_info_always("Error in Engine Init\n");
+		nss_crypto_reset_state(&gbl_crypto_ctrl);
+		return -ENOMEM;
+	}
+
+	eng_count++;
+	gbl_crypto_ctrl.num_eng = eng_count;
+
+	return 0;
+}
+
+/*
+ * nss_crypto_remove()
+ *	remove the crypto engine and deregister everything
+ */
+static int nss_crypto_remove(struct platform_device *pdev)
+{
+	struct nss_crypto_ctrl_eng *e_ctrl;
+	struct nss_crypto_ctrl *ctrl;
+
+	e_ctrl = platform_get_drvdata(pdev);
+
+	/*
+	 * free clock references if any
+	 */
+	ctrl = container_of(&e_ctrl, struct nss_crypto_ctrl, eng);
+	if (ctrl->clocks) {
+		kfree(ctrl->clocks);
+	}
+
+	return 0;
+};
+
+static struct of_device_id nss_crypto_dt_ids[] = {
+	{ .compatible =  "qcom,nss-crypto" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, nss_crypto_dt_ids);
+
+/*
+ * platform device instance
+ */
+static struct platform_driver nss_crypto_drv = {
+	.probe  	= nss_crypto_probe,
+	.remove 	= nss_crypto_remove,
+	.driver 	= {
+		.owner	= THIS_MODULE,
+		.name	= "nss-crypto",
+		.of_match_table = of_match_ptr(nss_crypto_dt_ids),
+	},
+};
+
+/*
+ * nss_crypto_delayed_init
+ * 	delayed sequence to initialize crypto after NSS FW is initialized
+ */
+void nss_crypto_delayed_init(struct work_struct *work)
+{
+	struct nss_crypto_ctrl *ctrl;
+	uint32_t status = 0;
+	uint32_t i = 0;
+
+	ctrl = container_of(to_delayed_work(work), struct nss_crypto_ctrl, crypto_work);
+
+	/*
+	 * check if NSS FW is initialized
+	 */
+	if (nss_get_state(nss_drv_hdl) != NSS_STATE_INITIALIZED) {
+		schedule_delayed_work(&ctrl->crypto_work, msecs_to_jiffies(CRYPTO_DELAYED_INIT_TIME));
+		return;
+	}
+
+	nss_crypto_info_always("NSS Firmware initialized\n");
+
+	/*
+	 * reserve the index if certain pipe pairs are locked out for
+	 * trust zone use
+	 */
+	memset(ctrl->idx_bitmap, 0, sizeof(ctrl->idx_bitmap));
+
+	status = platform_driver_register(&nss_crypto_drv);
+	if (status) {
+		nss_crypto_err("unable to register the driver : %d\n", status);
+		return;
+	}
+
+	/*
+	 * If crypto probe has failed, no need for further initialization
+	 */
+	if (nss_crypto_check_state(ctrl, NSS_CRYPTO_STATE_NOT_READY)) {
+		nss_crypto_warn("%p:NSS Crypto probe failed, num_eng (%d)\n", ctrl, gbl_crypto_ctrl.num_eng);
+		return;
+	}
+
+	nss_crypto_set_state(ctrl, NSS_CRYPTO_STATE_INITIALIZED);
+	nss_crypto_user_attach_all(ctrl);
+
+	/*
+	 * Initialize the engine stats
+	 */
+	for (i = 0; i < ctrl->num_eng ; i++)
+		nss_crypto_debugfs_add_engine(ctrl, i);
+}
+
+/*
+ * nss_crypto_module_init()
+ *	module init for crypto driver
+ */
+static int __init nss_crypto_module_init(void)
+{
+	struct device_node *np;
+
+	nss_crypto_info_always("module loaded (platform - IPQ806x, build - %s)\n", NSS_CRYPTO_BUILD_ID);
+
+	nss_crypto_reset_state(&gbl_crypto_ctrl);
+
+	np = of_find_compatible_node(NULL, NULL, "qcom,nss-crypto");
+	if (!np) {
+		nss_crypto_info_always("qca-nss-crypto.ko is loaded for symbol link\n");
+		return 0;
+	}
+
+	nss_crypto_init();
+
+	nss_crypto_set_state(&gbl_crypto_ctrl, NSS_CRYPTO_STATE_READY);
+
+	nss_crypto_info_always("Register with NSS driver-\n");
+
+	INIT_DELAYED_WORK(&gbl_crypto_ctrl.crypto_work, nss_crypto_delayed_init);
+
+	schedule_delayed_work(&gbl_crypto_ctrl.crypto_work, msecs_to_jiffies(CRYPTO_DELAYED_INIT_TIME));
+
+	return 0;
+}
+
+/*
+ * nss_crypto_module_exit()
+ *	module exit for crypto driver
+ */
+static void __exit nss_crypto_module_exit(void)
+{
+	nss_crypto_info("module unloaded (IPQ806x)\n");
+
+	platform_driver_unregister(&nss_crypto_drv);
+}
+
+module_init(nss_crypto_module_init);
+module_exit(nss_crypto_module_exit);
+
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_DESCRIPTION("QCA NSS Crypto driver");
diff --git a/drivers/crypto/nss/nss_crypto_hlos.h b/drivers/crypto/nss/nss_crypto_hlos.h
new file mode 100644
index 0000000..df7ff3b
--- /dev/null
+++ b/drivers/crypto/nss/nss_crypto_hlos.h
@@ -0,0 +1,82 @@
+/* Copyright (c) 2013, 2016, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+ * AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT
+ * INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+ * LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
+ * OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+ * PERFORMANCE OF THIS SOFTWARE.
+ *
+ *
+ */
+#ifndef __NSS_CRYPTO_HLOS_H
+#define __NSS_CRYPTO_HLOS_H
+
+#include <linux/version.h>
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,38) && !defined(AUTOCONF_INCLUDED)
+#include<linux/config.h>
+#endif
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/random.h>
+#include <linux/skbuff.h>
+#include <linux/moduleparam.h>
+#include <linux/spinlock.h>
+#include <asm/cmpxchg.h>
+#include <linux/slab.h>
+#include <linux/llist.h>
+#include <linux/vmalloc.h>
+#include <linux/debugfs.h>
+
+
+#define NSS_CRYPTO_DEBUG_LVL_ERROR 1
+#define NSS_CRYPTO_DEBUG_LVL_WARN 2
+#define NSS_CRYPTO_DEBUG_LVL_INFO 3
+#define NSS_CRYPTO_DEBUG_LVL_TRACE 4
+
+#define nss_crypto_info_always(s, ...) pr_notice("<NSS-CRYPTO>:" s, ##__VA_ARGS__)
+
+#define nss_crypto_err(s, ...) do { \
+	if (net_ratelimit()) {  \
+		pr_alert("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__);	\
+	}	\
+} while (0)
+
+#define nss_crypto_warn(s, ...) do { \
+	if (net_ratelimit()) {  \
+		pr_warn("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__);	\
+	}	\
+} while (0)
+
+#if defined(CONFIG_DYNAMIC_DEBUG)
+/*
+ * Compile messages for dynamic enable/disable
+ */
+#define nss_crypto_info(s, ...) pr_debug("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+#define nss_crypto_trace(s, ...) pr_debug("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__)
+
+#else
+/*
+ * Statically compile messages at different levels
+ */
+#define nss_crypto_info(s, ...) {	\
+	if (NSS_CRYPTO_DEBUG_LEVEL > NSS_CRYPTO_DEBUG_LVL_INFO) {	\
+		pr_notice("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__);	\
+	}	\
+}
+#define nss_crypto_trace(s, ...) {	\
+	if (NSS_CRYPTO_DEBUG_LEVEL > NSS_CRYPTO_DEBUG_LVL_TRACE) {	\
+		pr_info("%s[%d]:" s, __FUNCTION__, __LINE__, ##__VA_ARGS__);	\
+	}	\
+}
+
+#endif /* !CONFIG_DYNAMIC_DEBUG */
+
+#endif /* __NSS_CRYPTO_HLOS_H */
diff --git a/drivers/crypto/nss/nss_crypto_hw.h b/drivers/crypto/nss/nss_crypto_hw.h
new file mode 100644
index 0000000..98d8cd7
--- /dev/null
+++ b/drivers/crypto/nss/nss_crypto_hw.h
@@ -0,0 +1,296 @@
+/* Copyright (c) 2013, 2017, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+ * AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT
+ * INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+ * LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
+ * OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+ * PERFORMANCE OF THIS SOFTWARE.
+ *
+ *
+ */
+#ifndef __NSS_CRYPTO_HW_H
+#define __NSS_CRYPTO_HW_H
+
+/**
+ * H/W registers & values
+ */
+#define CRYPTO_MASK_ALL				~((uint32_t)(0))
+#define CRYPTO_MAX_BURST			64
+
+#define CRYPTO_BURST2BEATS(x)			((x >> 3) - 1)
+
+#define CRYPTO_CONFIG_REQ_SIZE(x)		(x << 17)
+#define CRYPTO_CONFIG_DOUT_INTR			(0x1 << 3)
+#define CRYPTO_CONFIG_DIN_INTR			(0x1 << 2)
+#define CRYPTO_CONFIG_DOP_INTR			(0x1 << 1)
+#define CRYPTO_CONFIG_HIGH_SPEED_EN		(0x1 << 4)
+#define CRYPTO_CONFIG_PIPE_SEL(x)		(x << 5)
+#define CRYPTO_CONFIG_LITTLE_ENDIAN		(0x1 << 9)
+#define CRYPTO_CONFIG_MAX_REQS(x)		(x << 14)
+#define CRYPTO_CONFIG_RESET			0xE001F
+
+#define CRYPTO_ENCR_SEG_CFG_ALG_DES		0x1
+#define CRYPTO_ENCR_SEG_CFG_ALG_AES		0x2
+#define CRYPTO_ENCR_SEG_CFG_KEY_AES128		(0x0 << 3)
+#define CRYPTO_ENCR_SEG_CFG_KEY_AES256		(0x2 << 3)
+#define CRYPTO_ENCR_SEG_CFG_KEY_SINGLE_DES	(0x0 << 3)
+#define CRYPTO_ENCR_SEG_CFG_KEY_TRIPLE_DES	(0x1 << 3)
+#define CRYPTO_ENCR_SEG_CFG_MODE_ECB		(0x0 << 6)
+#define CRYPTO_ENCR_SEG_CFG_MODE_CBC		(0x1 << 6)
+#define CRYPTO_ENCR_SEG_CFG_MODE_CTR		(0x2 << 6)
+#define CRYPTO_ENCR_SEG_CFG_MODE_XTS		(0x3 << 6)
+#define CRYPTO_ENCR_SEG_CFG_MODE_CCM		(0x4 << 6)
+#define CRYPTO_ENCR_SEG_CFG_ENC			(0x1 << 10)
+#define CRYPTO_ENCR_SEG_CFG_PIPE_KEYS		(0x1 << 15)
+
+#define CRYPTO_SET_ENCRYPT(cfg)			((cfg) |= CRYPTO_ENCR_SEG_CFG_ENC)
+#define CRYPTO_SET_DECRYPT(cfg)			((cfg) &= ~CRYPTO_ENCR_SEG_CFG_ENC)
+
+#define CRYPTO_GOPROC_SET			0x1
+#define CRYPTO_GOPROC_CLR_CNTXT			(0x1 << 1)
+#define CRYPTO_GOPROC_RESULTS_DUMP		(0x1 << 2)
+
+#define CRYPTO_AUTH_SEG_CFG_ALG_SHA		0x1
+#define CRYPTO_AUTH_SEG_CFG_MODE_HMAC		(0x1 << 6)
+#define CRYPTO_AUTH_SEG_CFG_SIZE_SHA1		(0x0 << 9)
+#define CRYPTO_AUTH_SEG_CFG_SIZE_SHA2		(0x1 << 9)
+#define CRYPTO_AUTH_SEG_CFG_POS_BEFORE		(0x0 << 14)
+#define CRYPTO_AUTH_SEG_CFG_POS_AFTER		(0x1 << 14)
+#define CRYPTO_AUTH_SEG_CFG_LAST		(0x1 << 16)
+#define CRYPTO_AUTH_SEG_CFG_FIRST		(0x1 << 17)
+#define CRYPTO_AUTH_SEG_CFG_PIPE_KEYS		(0x1 << 19)
+
+#define CRYPTO_BAM_DESC_INT			(0x1 << 15)
+#define CRYPTO_BAM_DESC_EOT			(0x1 << 14)
+#define CRYPTO_BAM_DESC_EOB			(0x1 << 13)
+#define CRYPTO_BAM_DESC_NWD			(0x1 << 12)
+#define CRYPTO_BAM_DESC_CMD			(0x1 << 11)
+#define CRYPTO_BAM_DESC_LOCK			(0x1 << 10)
+#define CRYPTO_BAM_DESC_UNLOCK			(0x1 << 9)
+
+#define CRYPTO_BAM_P_CTRL_EN			(0x1 << 1)
+#define CRYPTO_BAM_P_CTRL_SYS_MODE		(0x1 << 5)
+#define CRYPTO_BAM_P_CTRL_DIRECTION(n)		((n & 0x1) << 3)
+#define CRYPTO_BAM_P_CTRL_LOCK_GROUP(n)		(n << 16)
+#define CRYPTO_BAM_DESC_CNT_TRSHLD_VAL		64
+#define	CRYPTO_BAM_CNFG_BITS_BAM_FULL_PIPE	(1 << 11)
+
+#define CRYPTO_ADDR_MSK				0x00FFFFFF
+#define CRYPTO_CMD_ADDR(addr)		((addr) & CRYPTO_ADDR_MSK)
+
+#define CRYPTO_BASE			0x1A000
+#define CRYPTO_SEG_SIZE			(CRYPTO_BASE + 0x110)
+#define CRYPTO_GO_PROC			(CRYPTO_BASE + 0x120)
+#define CRYPTO_ENCR_SEG_CFG		(CRYPTO_BASE + 0x200)
+#define CRYPTO_ENCR_SEG_SIZE		(CRYPTO_BASE + 0x204)
+#define CRYPTO_ENCR_SEG_START		(CRYPTO_BASE + 0x208)
+#define CRYPTO_ENCR_CNTRn_IVn(n)	(CRYPTO_BASE + 0x20C + (0x4 * n))
+#define CRYPTO_ENCR_CNTR_MASK		(CRYPTO_BASE + 0x21c)
+#define CRYPTO_ENCR_CCM_INIT_CNTRn(n)	(CRYPTO_BASE + 0x220 + (0x4 * n))
+#define CRYPTO_AUTH_SEG_CFG		(CRYPTO_BASE + 0x300)
+#define CRYPTO_AUTH_SEG_SIZE 		(CRYPTO_BASE + 0x304)
+#define CRYPTO_AUTH_SEG_START		(CRYPTO_BASE + 0X308)
+#define CRYPTO_AUTH_IVn(n)		(CRYPTO_BASE + 0x310 + (0x4 * n))
+#define CRYPTO_AUTH_INFO_NONCEn(n)	(CRYPTO_BASE + 0x350 + (0x4 * n))
+#define CRYPTO_CONFIG			(CRYPTO_BASE + 0x400)
+#define CRYPTO_ENCR_KEYn(n)		(CRYPTO_BASE + 0x3000 + (0x4 * n))
+#define CRYPTO_AUTH_KEYn(n)		(CRYPTO_BASE + 0x3040 + (0x4 * n))
+#define CRYPTO_ENCR_PIPEm_KEYn(m, n)	(CRYPTO_BASE + 0x4000 + (0x20 * m) + (0x4 * n))
+#define CRYPTO_AUTH_PIPEm_KEYn(m, n)	(CRYPTO_BASE + 0x4800 + (0x80 * m) + (0x4 * n))
+#define CRYPTO_STATUS			(CRYPTO_BASE + 0x100)
+#define CRYPTO_STATUS2			(CRYPTO_BASE + 0x104)
+#define CRYPTO_DEBUG_ENABLE		(CRYPTO_BASE + 0x5000)
+#define CRYPTO_DEBUG_STATUS		(CRYPTO_BASE + 0x5004)
+
+#define CRYPTO_BAM_P_EVNT_REG(n)	(0x1818 + (0x1000 * n))
+#define CRYPTO_BAM_P_DESC_FIFO_ADDR(n)	(0x181c + (0x1000 * n))
+#define CRYPTO_BAM_P_FIFO_SIZES(n)	(0x1820 + (0x1000 * n))
+#define CRYPTO_BAM_P_SW_OFSTS(n)	(0x1800 + (0x1000 * n))
+#define CRYPTO_BAM_P_CTRL(n)            (0x1000 + (0x1000 * n))
+#define CRYPTO_BAM_P_RST(n)             (0x1004 + (0x1000 * n))
+
+#define CRYPTO_BAM_CTRL			0x0
+#define CRYPTO_BAM_DESC_CNT_TRSHLD	0x8
+#define CRYPTO_BAM_CNFG_BITS		0x7c
+
+#define CRYPTO_BAM_CTRL_SW_RST		(0x1 << 0)
+#define CRYPTO_BAM_CTRL_BAM_EN		(0x1 << 1)
+
+/**
+ * H/W specific information
+ */
+#define NSS_CRYPTO_CIPHER_IV_REGS	4 /**< cipher IV regs*/
+#define NSS_CRYPTO_AUTH_IV_REGS		8 /**< auth IV regs*/
+
+#define NSS_CRYPTO_CKEY_REGS		8 /**< cipher key regs*/
+#define NSS_CRYPTO_AKEY_REGS		8 /**< auth key regs*/
+
+#define NSS_CRYPTO_BCNT_REGS		2
+
+#define NSS_CRYPTO_CKEY_SZ		(NSS_CRYPTO_CKEY_REGS * sizeof(uint32_t))
+#define NSS_CRYPTO_AKEY_SZ		(NSS_CRYPTO_AKEY_REGS * sizeof(uint32_t))
+
+#define NSS_CRYPTO_RESULTS_SZ		sizeof(struct nss_crypto_res_dump)
+#define NSS_CRYPTO_INDESC_SZ		sizeof(struct nss_crypto_in_trans)
+#define NSS_CRYPTO_OUTDESC_SZ		sizeof(struct nss_crypto_out_trans)
+#define NSS_CRYPTO_BAM_DESC_SZ		sizeof(struct nss_crypto_bam_desc)
+#define NSS_CRYPTO_BAM_CMD_SZ		sizeof(struct nss_crypto_bam_cmd)
+#define NSS_CRYPTO_DESC_SZ		sizeof(struct nss_crypto_desc)
+#define NSS_CRYPTO_DESC_ALIGN		8
+#define NSS_CRYPTO_CACHE_CMD_SZ		offsetof(struct nss_crypto_cmd_config, keys)
+#define NSS_CRYPTO_UNCACHE_CMD_SZ	sizeof(struct nss_crypto_cmd_config)
+#define NSS_CRYPTO_CMD_REQ_SZ		offsetof(struct nss_crypto_cmd_request, unlock)
+#define NSS_CRYPTO_CMD_UNLOCK_SZ	NSS_CRYPTO_BAM_CMD_SZ
+
+#define NSS_CRYPTO_NUM_INDESC		(NSS_CRYPTO_INDESC_SZ / NSS_CRYPTO_BAM_DESC_SZ)
+#define NSS_CRYPTO_NUM_OUTDESC		(NSS_CRYPTO_OUTDESC_SZ / NSS_CRYPTO_BAM_DESC_SZ)
+#define NSS_CRYPTO_NUM_AUTH_IV		16
+#define NSS_CRYPTO_NUM_AUTH_BYTECNT	4
+#define NSS_CRYPTO_NUM_ENCR_CTR		4
+#define NSS_CRYPTO_NUM_STATUS		2
+
+#define NSS_CRYPTO_INPIPE(_pipe)	((_pipe) - ((_pipe) & 0x1))
+#define NSS_CRYPTO_OUTPIPE(_pipe)	(NSS_CRYPTO_INPIPE((_pipe)) + 1)
+
+
+/**
+ * @brief BAM pipe id constants for different pipe pairs as defined
+ * by the H/W specification 'NSS_CRYPTO_BAM_{IN/OUT}PIPE_<pipe pair index>'
+ */
+enum nss_crypto_bam_pipe_id {
+	NSS_CRYPTO_BAM_INPIPE_0 = 0,
+	NSS_CRYPTO_BAM_OUTPIPE_0 = 1,
+	NSS_CRYPTO_BAM_INPIPE_1 = 2,
+	NSS_CRYPTO_BAM_OUTPIPE_1 = 3,
+	NSS_CRYPTO_BAM_INPIPE_2 = 4,
+	NSS_CRYPTO_BAM_OUTPIPE_2 = 5,
+	NSS_CRYPTO_BAM_INPIPE_3 = 6,
+	NSS_CRYPTO_BAM_OUTPIPE_3 = 7
+};
+
+/**
+ * @brief crypto BAM descriptor
+ */
+struct nss_crypto_bam_desc {
+	uint32_t data_start;	/**< Start of Data*/
+	uint16_t data_len;	/**< Length of Data*/
+	uint16_t flags;		/**< Status Flags*/
+};
+
+/**
+ * @brief crypto BAM cmd descriptor
+ */
+struct nss_crypto_bam_cmd {
+	uint32_t addr;		/**< Address to access*/
+	uint32_t value;		/**< Addr (for read) or Data (for write)*/
+	uint32_t mask;		/**< mask to identify valid bits*/
+	uint32_t reserve;	/**< reserved*/
+};
+
+/**
+ * @brief keys command block, both encryption and authentication keys
+ * 	  are kept for uncached mode
+ */
+struct nss_crypto_cmd_keys {
+	struct nss_crypto_bam_cmd encr[NSS_CRYPTO_CKEY_REGS];	/**< encryption keys */
+	struct nss_crypto_bam_cmd auth[NSS_CRYPTO_AKEY_REGS];	/**< authentication keys */
+};
+
+/**
+ * @brief common configuration command block
+ */
+struct nss_crypto_cmd_config {
+	struct nss_crypto_bam_cmd config_0;				/**< config */
+
+	struct nss_crypto_bam_cmd encr_seg_cfg;				/**< encryption config */
+	struct nss_crypto_bam_cmd auth_seg_cfg;				/**< authentication config */
+
+	struct nss_crypto_bam_cmd encr_seg_start;			/**< encryption start offset */
+	struct nss_crypto_bam_cmd auth_seg_start;			/**< authentication start offset */
+
+	struct nss_crypto_bam_cmd encr_ctr_msk;				/**< encryption counter mask */
+	struct nss_crypto_bam_cmd auth_iv[NSS_CRYPTO_AUTH_IV_REGS];	/**< authentication IVs */
+
+	struct nss_crypto_cmd_keys keys;				/**< cipher & auth keys for uncached */
+};
+
+/**
+ * @brief per request configuration command block
+ */
+struct nss_crypto_cmd_request {
+	struct nss_crypto_bam_cmd seg_size;				/**< total segment size */
+	struct nss_crypto_bam_cmd encr_seg_size;			/**< encryption size */
+	struct nss_crypto_bam_cmd auth_seg_size;			/**< authentication size */
+
+	struct nss_crypto_bam_cmd encr_iv[NSS_CRYPTO_CIPHER_IV_REGS];	/**< encryption IVs */
+
+	struct nss_crypto_bam_cmd config_1;				/**< config, used to switch into little endian */
+	struct nss_crypto_bam_cmd go_proc;				/**< crypto trigger, marking config loaded */
+	struct nss_crypto_bam_cmd unlock;				/**< dummy write for unlock*/
+};
+
+/**
+ * @brief crypto command block structure, there is '1' instance of common configuration as it
+ * 	  doesn't change per request and there is 'n' request command blocks that change on
+ * 	  each request
+ */
+struct nss_crypto_cmd_block {
+	struct nss_crypto_cmd_config cfg;
+	struct nss_crypto_cmd_request req[NSS_CRYPTO_MAX_QDEPTH];
+};
+
+
+/**
+ * @brief results dump format, generated at the end of the operation
+ * 	  as an optimization we place the results dump at the end of
+ * 	  the packet. The IV contains the generated hash of the operation
+ */
+struct nss_crypto_res_dump {
+	uint32_t auth_iv[NSS_CRYPTO_NUM_AUTH_IV];
+	uint32_t byte_cnt[NSS_CRYPTO_NUM_AUTH_BYTECNT];
+	uint32_t encr_ctr[NSS_CRYPTO_NUM_ENCR_CTR];
+	uint32_t status[NSS_CRYPTO_NUM_STATUS];
+	uint8_t burst_pad[24]; 				/**< XXX:pad based upon the burst size*/
+};
+
+/**
+ * @brief input transaction set
+ */
+struct nss_crypto_in_trans {
+	struct nss_crypto_bam_desc cmd0_lock;	/**< main cmds & lock pipe*/
+	struct nss_crypto_bam_desc cmd1;	/**< secondary commands */
+	struct nss_crypto_bam_desc data;	/**< data*/
+	struct nss_crypto_bam_desc cmd2_unlock;	/**< unlock pipe */
+};
+
+/**
+ * @brief output transaction set
+ */
+struct nss_crypto_out_trans {
+	struct nss_crypto_bam_desc data;
+	struct nss_crypto_bam_desc results;
+};
+
+/**
+ * @brief set of descriptors, this gets allocated in one chunk
+ *
+ * @note  future implementation will decouple all this into separate memory
+ *        allocations done from various memories (like DDR, NSS_TCM, Krait L2)
+ */
+struct nss_crypto_desc {
+	struct nss_crypto_in_trans in[NSS_CRYPTO_MAX_QDEPTH];
+	struct nss_crypto_out_trans out[NSS_CRYPTO_MAX_QDEPTH];
+};
+
+#define nss_crypto_idx_to_inpipe(_idx)		((_idx) << 1)
+#define nss_crypto_idx_to_outpipe(_idx)		(((_idx) << 1) + 1)
+#define nss_crypto_inpipe_to_idx(_in)		((_in) >> 1)
+
+#endif /* __NSS_CRYPTO_HW_H*/
diff --git a/drivers/crypto/nss/nss_crypto_if.c b/drivers/crypto/nss/nss_crypto_if.c
new file mode 100644
index 0000000..6660499
--- /dev/null
+++ b/drivers/crypto/nss/nss_crypto_if.c
@@ -0,0 +1,738 @@
+/*
+ * Copyright (c) 2013-2017, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+ * AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT
+ * INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+ * LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
+ * OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+ * PERFORMANCE OF THIS SOFTWARE.
+ *
+ */
+#include <nss_crypto_hlos.h>
+#include <nss_api_if.h>
+#include <nss_crypto.h>
+#include <nss_crypto_if.h>
+#include <nss_crypto_hw.h>
+#include <nss_crypto_ctrl.h>
+#include <nss_crypto_dbg.h>
+#include <nss_crypto_debugfs.h>
+
+#define NSS_CRYPTO_DEBUGFS_PERM_RO 0444
+#define NSS_CRYPTO_DEBUGFS_PERM_RW 0666
+#define NSS_CRYPTO_MSG_LEN (sizeof(struct nss_crypto_msg) - sizeof(struct nss_cmn_msg))
+
+#define NSS_CRYPTO_ZONE_NAME_LEN	64
+#define NSS_CRYPTO_ZONE_DEFAULT_NAME	"crypto_buf-"
+
+/*
+ * global control component
+ */
+extern struct nss_crypto_ctrl gbl_crypto_ctrl;
+
+struct nss_ctx_instance *nss_drv_hdl;
+
+struct nss_crypto_drv_ctx gbl_ctx = {0};
+
+/*
+ * internal structure for a buffer node
+ */
+struct nss_crypto_buf_node {
+	struct llist_node node;			/* lockless node */
+	struct sk_buff *skb;			/* SKB for holding the Crypto buffer */
+	uint8_t results[NSS_CRYPTO_RESULTS_SZ] __attribute__((aligned(L1_CACHE_BYTES)));
+};
+
+#define NSS_CRYPTO_BUF_MAP_LEN \
+	(offsetof(struct nss_crypto_buf_node, results) - offsetof(struct nss_crypto_buf_node, buf))
+
+#define NSS_CRYPTO_RESULTS_MAP_LEN L1_CACHE_BYTES
+
+/*
+ * users of crypto driver
+ */
+struct nss_crypto_user {
+	struct list_head  node;			/* user list */
+	struct llist_head pool_head;	/* buffer pool lockless list */
+
+	nss_crypto_user_ctx_t ctx;		/* user specific context*/
+
+	nss_crypto_attach_t attach;		/* attach function*/
+	nss_crypto_detach_t detach;		/* detach function*/
+
+	struct kmem_cache *zone;
+	uint8_t zone_name[NSS_CRYPTO_ZONE_NAME_LEN];
+};
+
+LIST_HEAD(nss_crypto_user_head);
+
+/*
+ * This pool seed indicates that we have 1024 SKBs per
+ * user. These 1024 SKBs are preallocated per user and
+ * maintained in a list. If a particular user does not
+ * find a free SKB from this preallocated pool, it will
+ * try to allocate a new one.
+ */
+static uint32_t nss_crypto_pool_seed = 1024;
+
+/*
+ * nss_crypto_buf_init
+ *	Initialize the allocated crypto buffer
+ */
+static inline void nss_crypto_buf_init(struct nss_crypto_buf_node *entry, struct nss_crypto_buf *buf)
+{
+	BUG_ON(((uint32_t)entry->results % L1_CACHE_BYTES));
+
+	buf->ctx_0 = (uint32_t)entry;
+	buf->origin = NSS_CRYPTO_BUF_ORIGIN_HOST;
+
+	buf->hash_addr = (uint32_t)entry->results;
+	buf->iv_addr = (uint32_t)entry->results;
+}
+
+/*
+ * nss_crypto_user_attach_all()
+ *	Helper API for user to attach with crypto
+ */
+void nss_crypto_user_attach_all(struct nss_crypto_ctrl *ctrl)
+{
+	nss_crypto_user_ctx_t *ctx = NULL;
+	struct nss_crypto_user *user, *tmp;
+
+	BUG_ON(!(nss_crypto_check_state(ctrl, NSS_CRYPTO_STATE_INITIALIZED)));
+
+	/*
+	 * Walk the list of users and call the attach if they are not called yet
+	 */
+	mutex_lock(&ctrl->mutex);
+	list_for_each_entry_safe(user, tmp, &nss_crypto_user_head, node) {
+		if (user->ctx) {
+			continue;
+		}
+
+		mutex_unlock(&ctrl->mutex);
+		ctx = user->attach(user);
+		mutex_lock(&ctrl->mutex);
+
+		if (ctx) {
+			user->ctx = ctx;
+		}
+
+	}
+
+	mutex_unlock(&ctrl->mutex);
+}
+
+/*
+ * nss_crypto_register_user()
+ * 	register a new user of the crypto driver
+ */
+void nss_crypto_register_user(nss_crypto_attach_t attach, nss_crypto_detach_t detach, uint8_t *user_name)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	nss_crypto_user_ctx_t *ctx = NULL;
+	struct nss_crypto_buf_node *entry;
+	struct nss_crypto_user *user;
+	struct nss_crypto_buf *buf;
+	int i;
+
+	if (nss_crypto_check_state(ctrl, NSS_CRYPTO_STATE_NOT_READY)) {
+		nss_crypto_warn("%p: Crypto Device is not ready\n", ctrl);
+		return;
+	}
+
+	user = vzalloc(sizeof(struct nss_crypto_user));
+	if (!user) {
+		nss_crypto_warn("%p:memory allocation fails for user(%s)\n", ctrl, user_name);
+		return;
+	}
+
+	user->attach = attach;
+	user->detach = detach;
+	user->ctx = NULL;
+
+	strlcpy(user->zone_name, NSS_CRYPTO_ZONE_DEFAULT_NAME, NSS_CRYPTO_ZONE_NAME_LEN);
+
+	/*
+	 * initialize list elements
+	 */
+	INIT_LIST_HEAD(&user->node);
+	init_llist_head(&user->pool_head);
+
+	/*
+	 * Allocated the kmem_cache pool of crypto_bufs
+	 * XXX: we can use the constructor
+	 */
+	strlcat(user->zone_name, user_name, NSS_CRYPTO_ZONE_NAME_LEN);
+	user->zone = kmem_cache_create(user->zone_name, sizeof(struct nss_crypto_buf_node), 0, SLAB_HWCACHE_ALIGN, NULL);
+	if (!user->zone) {
+		nss_crypto_info_always("%p:(%s)failed to create crypto_buf for user\n", user, user_name);
+		goto fail;
+	}
+
+	/*
+	 * Try allocating till the seed value. If, the
+	 * system returned less buffers then it will be
+	 * taken care by the alloc routine by allocating
+	 * the addtional buffers.
+	 */
+	for (i = 0; i < nss_crypto_pool_seed; i++) {
+		entry = kmem_cache_alloc(user->zone, GFP_KERNEL);
+		if (!entry) {
+			nss_crypto_info_always("%p:failed to allocate memory\n", user);
+			break;
+		}
+
+		/*
+		 * We do not want to fail in case we are unable to allocate the
+		 * seed amount of SKBs. We would like to continue with whatever
+		 * SKBs that were allocated successfully.
+		 */
+		entry->skb = dev_alloc_skb(sizeof(struct nss_crypto_buf) + L1_CACHE_BYTES);
+		if (!entry->skb) {
+			kmem_cache_free(user->zone, entry);
+			break;
+		}
+
+		buf = (struct nss_crypto_buf *)skb_put(entry->skb, sizeof(struct nss_crypto_buf));
+
+		/*
+		 * Add to user local list.
+		 */
+		llist_add(&entry->node, &user->pool_head);
+		nss_crypto_buf_init(entry, buf);
+	}
+
+	mutex_lock(&ctrl->mutex);
+	list_add_tail(&user->node, &nss_crypto_user_head);
+
+	/*
+	 * this is required; if the crypto has not probed but a new
+	 * user comes and registers itself. In that case we add the
+	 * user to the 'user_head' and wait for the probe to complete.
+	 * Once the probe completes the 'user_attach_all' gets called
+	 * which initiates the attach for all users
+	 */
+	if (!nss_crypto_check_state(ctrl, NSS_CRYPTO_STATE_INITIALIZED)) {
+		mutex_unlock(&ctrl->mutex);
+		return;
+	}
+
+	/*
+	 * release the mutex before calling; if the attach tries to unregister
+	 * in the same call it will not deadlock
+	 */
+	mutex_unlock(&ctrl->mutex);
+	ctx = attach(user);
+	mutex_lock(&ctrl->mutex);
+
+	if (ctx) {
+		user->ctx = ctx;
+	}
+
+	mutex_unlock(&ctrl->mutex);
+	return;
+fail:
+	nss_crypto_unregister_user(user);
+	return;
+}
+EXPORT_SYMBOL(nss_crypto_register_user);
+
+/*
+ * nss_crypto_unregister_user()
+ * 	unregister a user from the crypto driver
+ */
+void nss_crypto_unregister_user(nss_crypto_handle_t crypto)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_buf_node *entry;
+	struct nss_crypto_user *user;
+	struct llist_node *node;
+
+	user = (struct nss_crypto_user *)crypto;
+
+	mutex_lock(&ctrl->mutex);
+	if (user->ctx && user->detach) {
+		user->detach(user->ctx);
+	}
+
+	list_del(&user->node);
+	mutex_unlock(&ctrl->mutex);
+
+	/*
+	 * The skb pool is a lockless list
+	 */
+	while (!llist_empty(&user->pool_head)) {
+		node = llist_del_first(&user->pool_head);
+		entry = container_of(node, struct nss_crypto_buf_node, node);
+
+		dev_kfree_skb_any(entry->skb);
+		kmem_cache_free(user->zone, entry);
+	}
+
+	/*
+	 * this will happen if we are unwinding in a error
+	 * path. Remove the user zone if it was successfully
+	 * allocated.
+	 */
+	if (user->zone) {
+		kmem_cache_destroy(user->zone);
+	}
+
+	vfree(user);
+}
+EXPORT_SYMBOL(nss_crypto_unregister_user);
+
+/*
+ * nss_crypto_buf_alloc()
+ * 	allocate a crypto buffer for its user
+ *
+ * the allocation happens from its user pool. If, a user runs out its pool
+ * then it will only be affected. Also, this function is lockless
+ */
+struct nss_crypto_buf *nss_crypto_buf_alloc(nss_crypto_handle_t hdl)
+{
+	struct nss_crypto_buf_node *entry;
+	struct nss_crypto_user *user;
+	struct nss_crypto_buf *buf;
+	struct llist_node *node;
+
+	user = (struct nss_crypto_user *)hdl;
+
+	node = llist_del_first(&user->pool_head);
+	if (node) {
+		entry = container_of(node, struct nss_crypto_buf_node, node);
+		goto done;
+	}
+
+	/*
+	 * Note: this condition is hit when there are more than 'seed' worth
+	 * of crypto buffers outstanding with the system. Instead of failing
+	 * allocation attempt allocating buffers so that pool grows itself
+	 * to the right amount needed to sustain the traffic without the need
+	 * for dynamic allocation in future requests
+	 */
+	entry = kmem_cache_alloc(user->zone, GFP_KERNEL);
+	if (!entry) {
+		nss_crypto_info("%p:(%s)Unable to allocate crypto buffer from cache\n", user, user->zone_name);
+		return NULL;
+	}
+
+	entry->skb = dev_alloc_skb(sizeof(struct nss_crypto_buf) + L1_CACHE_BYTES);
+	if (!entry->skb) {
+		nss_crypto_info("%p:Unable to allocate skb\n", entry);
+		kmem_cache_free(user->zone, entry);
+		return NULL;
+	}
+
+done:
+	/*
+	 * we need to reset the buffer in all cases; as it will contain data
+	 * from previous transactions.
+	 */
+	buf = (struct nss_crypto_buf *)entry->skb->data;
+	nss_crypto_buf_init(entry, buf);
+	return buf;
+}
+EXPORT_SYMBOL(nss_crypto_buf_alloc);
+
+/*
+ * nss_crypto_buf_free()
+ * 	free the crypto buffer back to the user buf pool
+ */
+void nss_crypto_buf_free(nss_crypto_handle_t hdl, struct nss_crypto_buf *buf)
+{
+	struct nss_crypto_buf_node *entry;
+	struct nss_crypto_user *user;
+
+	user = (struct nss_crypto_user *)hdl;
+	entry = (struct nss_crypto_buf_node *)buf->ctx_0;
+
+	memset(buf, 0, sizeof(struct nss_crypto_buf));
+	memset(entry->results, 0, NSS_CRYPTO_MAX_HASHLEN);
+
+	llist_add(&entry->node, &user->pool_head);
+
+}
+EXPORT_SYMBOL(nss_crypto_buf_free);
+
+/*
+ * nss_crypto_transform_done()
+ * 	completion callback for NSS HLOS driver when it receives a crypto buffer
+ *
+ * this function assumes packets arriving from host are transform buffers that
+ * have been completed by the NSS crypto. It needs to have a switch case for
+ * detecting control packets also
+ */
+void nss_crypto_transform_done(struct net_device *dev, struct sk_buff *skb, struct napi_struct *napi)
+{
+	struct nss_crypto_buf *buf = (struct nss_crypto_buf *)skb->data;
+	struct nss_crypto_buf_node *entry;
+	void *addr;
+
+	if (likely(buf->data_in == buf->data_out)) {
+		dma_unmap_single(NULL, buf->data_in, buf->data_len, DMA_BIDIRECTIONAL);
+	} else {
+		dma_unmap_single(NULL, buf->data_in, buf->data_len, DMA_TO_DEVICE);
+		dma_unmap_single(NULL, buf->data_out, buf->data_len, DMA_FROM_DEVICE);
+	}
+
+	dma_unmap_single(NULL, buf->iv_addr,  L1_CACHE_BYTES, DMA_BIDIRECTIONAL);
+
+	addr = phys_to_virt(buf->iv_addr);
+	entry = container_of(addr, struct nss_crypto_buf_node, results);
+
+	buf->hash_addr = (uint32_t)addr;
+	buf->iv_addr = (uint32_t)addr;
+
+	buf->ctx_0 = (uint32_t)entry;
+
+	buf->cb_fn(buf);
+}
+
+/*
+ * nss_crypto_copy_stats()
+ * 	copy stats from msg to local copy.
+ */
+static void nss_crypto_copy_stats(void *dst, void *src)
+{
+	memcpy(dst, src, sizeof(struct nss_crypto_stats));
+}
+
+/*
+ * nss_crypto_process_sync()
+ *	callback function for sync messages.
+ */
+void nss_crypto_process_event(void *app_data, struct nss_crypto_msg *nim)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	struct nss_crypto_ctrl_eng *e_ctrl;
+	struct nss_crypto_idx_info *idx;
+	struct nss_crypto_sync_stats *stats;
+	int i;
+
+	switch (nim->cm.type) {
+	case NSS_CRYPTO_MSG_TYPE_STATS:
+
+		stats = &nim->msg.stats;
+
+		for (i = 0; i < ctrl->num_eng; i++) {
+			e_ctrl = &ctrl->eng[i];
+			nss_crypto_copy_stats(&e_ctrl->stats, &stats->eng_stats[i]);
+		}
+
+		for (i = 0; i < NSS_CRYPTO_MAX_IDXS; i++) {
+			idx = &ctrl->idx_info[i];
+
+			/*
+			 * Copy statistics only if session is active
+			 */
+			if (nss_crypto_chk_idx_isfree(idx) == true) {
+				continue;
+			}
+
+			nss_crypto_copy_stats(&idx->stats, &stats->idx_stats[i]);
+		}
+
+		nss_crypto_copy_stats(&ctrl->total_stats, &stats->total);
+
+		break;
+
+	default:
+		nss_crypto_err("unsupported sync type %d\n", nim->cm.type);
+		return;
+	}
+}
+
+/*
+ * nss_crypto_msg_sync_cb()
+ * 	callback handler for for NSS synchronous messages
+ */
+void nss_crypto_msg_sync_cb(void *app_data, struct nss_crypto_msg *nim)
+{
+	struct nss_crypto_msg *nim_resp = (struct nss_crypto_msg *)app_data;
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+
+	/*
+	 * make sure there was no timeout
+	 */
+	if (atomic_read(&ctrl->complete_timeo)) {
+		nss_crypto_dbg("response received after timeout (type - %d)\n", cm->type);
+		return;
+	}
+
+	memcpy(nim_resp, nim, sizeof(struct nss_crypto_msg));
+
+	complete(&ctrl->complete);
+}
+
+/*
+ * nss_crypto_send_msg_sync
+ * 	Send synchronous message to NSS.
+ */
+nss_crypto_status_t nss_crypto_send_msg_sync(struct nss_crypto_msg *nim, enum nss_crypto_msg_type type)
+{
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	int ret;
+
+	/*
+	 * only one caller will be allowed to send a message
+	 */
+	if (down_interruptible(&ctrl->sem)) {
+		nss_crypto_dbg("failed to acquire semaphore\n");
+		return NSS_CRYPTO_STATUS_FAIL;
+	}
+
+	nss_cmn_msg_init(&nim->cm, NSS_CRYPTO_INTERFACE, type, NSS_CRYPTO_MSG_LEN, nss_crypto_msg_sync_cb, nim);
+
+	if (nss_crypto_tx_msg(nss_drv_hdl, nim) != NSS_TX_SUCCESS) {
+		nss_crypto_dbg("failed to send message to NSS(type - %d)\n", type);
+		goto fail;
+	}
+
+	atomic_set(&ctrl->complete_timeo, 0);
+
+	ret = wait_for_completion_timeout(&ctrl->complete, NSS_CRYPTO_RESP_TIMEO_TICKS);
+	if (!ret) {
+		atomic_inc(&ctrl->complete_timeo);
+		nss_crypto_err("no response received from NSS(type - %d)\n", type);
+		goto fail;
+	}
+
+	/*
+	 * need to ensure that the response data has correctly arrived in
+	 * current CPU cache
+	 */
+	smp_rmb();
+
+	if (nim->cm.response != NSS_CMN_RESPONSE_ACK) {
+		nss_crypto_err("Error from NSS: resp code (%d) error code (%d) \n",
+				nim->cm.response, nim->cm.error);
+		goto fail;
+	}
+
+	up(&ctrl->sem);
+	return NSS_CRYPTO_STATUS_OK;
+
+fail:
+	up(&ctrl->sem);
+	return NSS_CRYPTO_STATUS_FAIL;
+}
+
+/*
+ * nss_crypto_transform_payload()
+ *	submit a transform for crypto operation to NSS
+ */
+nss_crypto_status_t nss_crypto_transform_payload(nss_crypto_handle_t crypto, struct nss_crypto_buf *buf)
+{
+	struct nss_crypto_buf_node *entry;
+	nss_tx_status_t nss_status;
+	uint32_t paddr;
+	void *vaddr;
+	size_t len;
+
+	if (!buf->cb_fn) {
+		nss_crypto_warn("%p:no buffer(%p) callback present\n", crypto, buf);
+		return NSS_CRYPTO_STATUS_FAIL;
+	}
+
+	entry = (struct nss_crypto_buf_node *)buf->ctx_0;
+
+	/*
+	 * map data IN address
+	 */
+	vaddr = (void *)buf->data_in;
+	len = buf->data_len;
+	paddr = dma_map_single(NULL, vaddr, len, DMA_TO_DEVICE);
+	buf->data_in = paddr;
+
+	if (vaddr == (void *)buf->data_out) {
+		buf->data_out = buf->data_in;
+	} else {
+		/*
+		 * map data OUT address
+		 */
+		vaddr = (void *)buf->data_out;
+		len = buf->data_len;
+		paddr = dma_map_single(NULL, vaddr, len, DMA_FROM_DEVICE);
+		buf->data_out = paddr;
+	}
+
+	/*
+	 * We need to map the results into IV
+	 */
+	paddr = dma_map_single(NULL, entry->results, L1_CACHE_BYTES, DMA_BIDIRECTIONAL);
+	buf->hash_addr = paddr;
+	buf->iv_addr = paddr;
+
+	/*
+	 * Crypto buffer is essentially sitting inside the "skb->data". So, there
+	 * is no need to MAP it here as it will be taken care by NSS driver
+	 */
+	nss_status = nss_crypto_tx_buf(nss_drv_hdl, NSS_CRYPTO_INTERFACE, entry->skb);
+	if (nss_status != NSS_TX_SUCCESS) {
+		nss_crypto_dbg("Not able to send crypto buf to NSS\n");
+		return NSS_CRYPTO_STATUS_FAIL;
+	}
+
+	return NSS_CRYPTO_STATUS_OK;
+}
+EXPORT_SYMBOL(nss_crypto_transform_payload);
+
+/*
+ * nss_crypto_init()
+ * 	initialize the crypto driver
+ *
+ * this will do the following
+ * - Bring Power management perf level to TURBO
+ * - register itself to the NSS HLOS driver
+ * - wait for the NSS to be ready
+ * - initialize the control component
+ */
+void nss_crypto_init(void)
+{
+	nss_crypto_ctrl_init();
+
+	gbl_ctx.pm_hdl = nss_pm_client_register(NSS_PM_CLIENT_CRYPTO);
+
+	/*
+	 * Initialize debugfs entries
+	 */
+	nss_crypto_debugfs_init(&gbl_crypto_ctrl);
+
+	nss_drv_hdl = nss_crypto_notify_register(nss_crypto_process_event, &nss_crypto_user_head);
+	nss_drv_hdl = nss_crypto_data_register(NSS_CRYPTO_INTERFACE, nss_crypto_transform_done, NULL, 0);
+}
+
+/*
+ * nss_crypto_engine_init()
+ * 	initialize the crypto interface for each engine
+ *
+ * this will do the following
+ * - prepare the open message for the engine
+ * - initialize the control component for all pipes in that engine
+ * - send the open message to the NSS crypto
+ */
+int nss_crypto_engine_init(uint32_t eng_num)
+{
+	struct nss_crypto_msg nim;
+	struct nss_crypto_config_eng *open = &nim.msg.eng;
+	struct nss_crypto_ctrl_eng *e_ctrl;
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	int i;
+
+	e_ctrl = &ctrl->eng[eng_num];
+
+	/*
+	 * prepare the open config message
+	 */
+	open->eng_id = eng_num;
+	open->bam_pbase = e_ctrl->bam_pbase;
+
+	for (i = 0; i < NSS_CRYPTO_BAM_PP; i++) {
+		nss_crypto_pipe_init(e_ctrl, i, &open->desc_paddr[i], &e_ctrl->hw_desc[i]);
+	}
+
+	if (nss_crypto_idx_init(e_ctrl, open->idx) != NSS_CRYPTO_STATUS_OK) {
+		nss_crypto_err("failed to initiallize\n");
+		return NSS_CRYPTO_STATUS_FAIL;
+	}
+
+	/*
+	 * send open config message to NSS crypto
+	 */
+	return nss_crypto_send_msg_sync(&nim, NSS_CRYPTO_MSG_TYPE_OPEN_ENG);
+}
+
+/*
+ * nss_crypto_send_session_update()
+ * 	reset session specific state (alloc or free)
+ */
+nss_crypto_status_t nss_crypto_send_session_update(uint32_t session_idx, enum nss_crypto_session_state state, enum nss_crypto_cipher algo)
+{
+	struct nss_crypto_msg nim;
+	struct nss_crypto_config_session *session = &nim.msg.session;
+	struct nss_crypto_ctrl *ctrl = &gbl_crypto_ctrl;
+	nss_crypto_status_t status;
+	uint32_t iv_len = 0;
+
+	switch (state) {
+	case NSS_CRYPTO_SESSION_STATE_ACTIVE:
+		nss_crypto_debugfs_add_session(ctrl, session_idx);
+		break;
+
+	case NSS_CRYPTO_SESSION_STATE_FREE:
+		nss_crypto_debugfs_del_session(ctrl, session_idx);
+		break;
+
+	default:
+		nss_crypto_err("incorrect session state = %d\n", state);
+		return NSS_CRYPTO_STATUS_FAIL;
+	}
+
+	switch (algo) {
+	case NSS_CRYPTO_CIPHER_AES_CBC:
+	case NSS_CRYPTO_CIPHER_AES_CTR:
+		iv_len = NSS_CRYPTO_MAX_IVLEN_AES;
+		break;
+
+	case NSS_CRYPTO_CIPHER_DES:
+		iv_len = NSS_CRYPTO_MAX_IVLEN_DES;
+		break;
+
+	case NSS_CRYPTO_CIPHER_NULL:
+		iv_len = NSS_CRYPTO_MAX_IVLEN_NULL;
+		break;
+
+	default:
+		nss_crypto_err("invalid cipher\n");
+		return NSS_CRYPTO_STATUS_FAIL;
+	}
+
+	session->idx = session_idx;
+	session->state = state;
+	session->iv_len = iv_len;
+
+	/*
+	 * send reset stats config message to NSS crypto
+	 */
+	status = nss_crypto_send_msg_sync(&nim, NSS_CRYPTO_MSG_TYPE_UPDATE_SESSION);
+	if (status != NSS_CRYPTO_STATUS_OK) {
+		nss_crypto_info_always("session(%d) update failed\n", session->idx);
+		return status;
+	}
+
+	/*
+	 * If NSS state has changed to free. Delete session resources
+	 */
+	if (session->state == NSS_CRYPTO_SESSION_STATE_FREE) {
+		nss_crypto_idx_free(session->idx);
+	}
+
+	return status;
+}
+
+/**
+ * @brief crypto buf get api for IV address
+ */
+uint8_t *nss_crypto_get_ivaddr(struct nss_crypto_buf *buf)
+{
+	return (uint8_t *)buf->iv_addr;
+}
+EXPORT_SYMBOL(nss_crypto_get_ivaddr);
+
+/**
+ * @brief crypto buf get api for hash address
+ */
+uint8_t *nss_crypto_get_hash_addr(struct nss_crypto_buf *buf)
+{
+	return (uint8_t *)buf->hash_addr;
+}
+EXPORT_SYMBOL(nss_crypto_get_hash_addr);
+
diff --git a/drivers/crypto/nss/nss_crypto_platform.c b/drivers/crypto/nss/nss_crypto_platform.c
new file mode 100644
index 0000000..27abe46
--- /dev/null
+++ b/drivers/crypto/nss/nss_crypto_platform.c
@@ -0,0 +1,296 @@
+/*
+ * Copyright (c) 2013,2015-2017, The Linux Foundation. All rights reserved.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+ * AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT
+ * INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+ * LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE
+ * OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+ * PERFORMANCE OF THIS SOFTWARE.
+ *
+ *
+ */
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/device.h>
+#include <linux/memory.h>
+#include <linux/io.h>
+#include <linux/clk.h>
+#include <linux/uaccess.h>
+#include <linux/dma-mapping.h>
+#include <linux/platform_device.h>
+#include <mach/msm_iomap.h>
+#include <mach/msm_nss_crypto.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/vmalloc.h>
+#include <nss_crypto_hlos.h>
+#include <nss_api_if.h>
+#include <nss_crypto.h>
+#include <nss_crypto_if.h>
+#include <nss_crypto_hw.h>
+#include <nss_crypto_ctrl.h>
+#include <nss_crypto_dbg.h>
+#include <nss_crypto_debugfs.h>
+
+#define REG(off)	(MSM_CLK_CTL_BASE + (off))
+#define REG_GCC(off)	(MSM_APCS_GCC_BASE + (off))
+
+#define CRYPTO_RESET_ENG(n)	REG(0x3E00 + (n * 0x4))
+#define CRYPTO_RESET_AHB	REG(0x3E10)
+
+#define CRYPTO_RESET_ENG_0	REG(0x3E00)
+#define CRYPTO_RESET_ENG_1	REG(0x3E04)
+#define CRYPTO_RESET_ENG_2	REG(0x3E08)
+#define CRYPTO_RESET_ENG_3	REG(0x3E0C)
+
+/* Poll time in ms */
+#define CRYPTO_DELAYED_INIT_TIME	100
+
+extern struct nss_crypto_ctrl gbl_crypto_ctrl;
+extern struct nss_ctx_instance *nss_drv_hdl;
+
+static int eng_count;
+
+int nss_crypto_engine_init(uint32_t eng_count);
+void nss_crypto_init(void);
+void nss_crypto_user_attach_all(struct nss_crypto_ctrl *ctrl);
+
+/*
+ * nss_crypto_bam_init()
+ * 	initialize the BAM for the given engine
+ */
+static void nss_crypto_bam_init(uint8_t *bam_iobase)
+{
+	uint32_t cfg_bits;
+	uint32_t ctrl_reg;
+
+	ctrl_reg = ioread32(bam_iobase + CRYPTO_BAM_CTRL);
+
+	ctrl_reg |= CRYPTO_BAM_CTRL_SW_RST;
+	iowrite32(ctrl_reg, bam_iobase + CRYPTO_BAM_CTRL);
+
+	ctrl_reg &= ~CRYPTO_BAM_CTRL_SW_RST;
+	iowrite32(ctrl_reg, bam_iobase + CRYPTO_BAM_CTRL);
+
+	ctrl_reg |= CRYPTO_BAM_CTRL_BAM_EN;
+	iowrite32(ctrl_reg, bam_iobase + CRYPTO_BAM_CTRL);
+
+	iowrite32(CRYPTO_BAM_DESC_CNT_TRSHLD_VAL, bam_iobase +  CRYPTO_BAM_DESC_CNT_TRSHLD);
+
+	/* disabling this is recommended from H/W specification*/
+	cfg_bits = ~((uint32_t)CRYPTO_BAM_CNFG_BITS_BAM_FULL_PIPE);
+	iowrite32(cfg_bits, bam_iobase + CRYPTO_BAM_CNFG_BITS);
+}
+
+/*
+ * nss_crypto_probe()
+ * 	probe routine called per engine from MACH-MSM
+ */
+static int nss_crypto_probe(struct platform_device *pdev)
+{
+	struct nss_crypto_ctrl_eng *e_ctrl;
+	struct nss_crypto_platform_data *res;
+	struct nss_crypto_ctrl_eng *eng_ptr;
+	int status = 0;
+	size_t old_sz;
+	size_t new_sz;
+
+	if (nss_crypto_check_state(&gbl_crypto_ctrl, NSS_CRYPTO_STATE_NOT_READY)) {
+		nss_crypto_info_always("exiting probe due to previous error\n");
+		return -ENOMEM;
+	}
+
+	nss_crypto_info_always("probing engine - %d\n", eng_count);
+	nss_crypto_assert(eng_count < NSS_CRYPTO_MAX_ENGINES);
+
+	eng_ptr = gbl_crypto_ctrl.eng;
+
+	old_sz = (gbl_crypto_ctrl.num_eng * sizeof(struct nss_crypto_ctrl_eng));
+	new_sz = old_sz + sizeof(struct nss_crypto_ctrl_eng);
+
+	eng_ptr = nss_crypto_mem_realloc(eng_ptr, old_sz, new_sz);
+	if (!eng_ptr) {
+		return -ENOMEM;
+	}
+
+	gbl_crypto_ctrl.eng = eng_ptr;
+
+	e_ctrl = &gbl_crypto_ctrl.eng[eng_count];
+	e_ctrl->dev = &pdev->dev;
+
+	/* crypto engine resources */
+	res = dev_get_platdata(e_ctrl->dev);
+	nss_crypto_assert(res);
+
+	e_ctrl->bam_ee = res->bam_ee;
+
+	e_ctrl->cmd_base = res->crypto_pbase;
+	e_ctrl->crypto_base = ioremap_nocache(res->crypto_pbase, res->crypto_pbase_sz);
+	nss_crypto_assert(e_ctrl->crypto_base);
+
+	e_ctrl->bam_pbase = res->bam_pbase;
+	e_ctrl->bam_base = ioremap_nocache(res->bam_pbase, res->bam_pbase_sz);
+	nss_crypto_assert(e_ctrl->bam_base);
+
+	/*
+	 * Link address of engine ctrl
+	 */
+	platform_set_drvdata(pdev, e_ctrl);
+
+	/*
+	 * intialize the BAM and the engine
+	 */
+	nss_crypto_bam_init(e_ctrl->bam_base);
+
+	if (nss_crypto_engine_init(eng_count) != NSS_CRYPTO_STATUS_OK) {
+		nss_crypto_info_always("Error in Engine Init\n");
+		nss_crypto_reset_state(&gbl_crypto_ctrl);
+		return -ENOMEM;
+	}
+
+	eng_count++;
+	gbl_crypto_ctrl.num_eng = eng_count;
+
+	return status;
+}
+
+/*
+ * nss_crypto_remove()
+ * 	remove the crypto engine and deregister everything
+ */
+static int nss_crypto_remove(struct platform_device *pdev)
+{
+	struct nss_crypto_ctrl_eng *ctrl;
+
+	ctrl = platform_get_drvdata(pdev);
+
+	/**
+	 * XXX: pipe deinit goes here
+	 */
+	return 0;
+};
+
+/*
+ * platform device instance
+ */
+static struct platform_driver nss_crypto_drv = {
+	.probe  	= nss_crypto_probe,
+	.remove 	= nss_crypto_remove,
+	.driver 	= {
+		.owner  = THIS_MODULE,
+		.name   = "nss-crypto",
+	},
+};
+
+/*
+ * nss_crypto_module_exit()
+ * 	module exit for crypto driver
+ */
+static void __exit nss_crypto_module_exit(void)
+{
+	nss_crypto_info("module unloaded (IPQ806x)\n");
+
+	platform_driver_unregister(&nss_crypto_drv);
+}
+
+/*
+ * nss_crypto_delayed_init()
+ *	Delayed worker function for crypto probe
+ */
+void nss_crypto_delayed_init(struct work_struct *work)
+{
+	struct nss_crypto_ctrl *ctrl;
+	uint32_t status = 0;
+	uint32_t i = 0;
+
+	ctrl = container_of(to_delayed_work(work), struct nss_crypto_ctrl, crypto_work);
+
+	/*
+	 * if NSS FW is not initialized at this point, schedule a delayed work
+	 * thread and wait for NSS FW to be up before doing a crypto probe
+	 */
+	if (nss_get_state(nss_drv_hdl) != NSS_STATE_INITIALIZED) {
+		schedule_delayed_work(&ctrl->crypto_work, msecs_to_jiffies(CRYPTO_DELAYED_INIT_TIME));
+		return;
+	}
+
+	nss_crypto_info_always("NSS Firmware initialized\n");
+
+	/*
+	 * reserve the index if certain pipe pairs are locked out for
+	 * trust zone use
+	 */
+	memset(ctrl->idx_bitmap, 0, sizeof(ctrl->idx_bitmap));
+
+	status = platform_driver_register(&nss_crypto_drv);
+	if (status) {
+		nss_crypto_err("unable to register the driver : %d\n", status);
+		return;
+	}
+
+	/*
+	 * If crypto probe has failed, no need for further initialization
+	 */
+	if (nss_crypto_check_state(ctrl, NSS_CRYPTO_STATE_NOT_READY)) {
+		nss_crypto_warn("%p:NSS Crypto probe failed, num_eng (%d)\n", ctrl, gbl_crypto_ctrl.num_eng);
+		return;
+	}
+
+	nss_crypto_set_state(ctrl, NSS_CRYPTO_STATE_INITIALIZED);
+	nss_crypto_user_attach_all(ctrl);
+
+	/*
+	 * Initialize the engine stats
+	 */
+	for (i = 0; i < ctrl->num_eng ; i++)
+		nss_crypto_debugfs_add_engine(ctrl, i);
+}
+
+/*
+ * nss_crypto_module_init()
+ * 	module init for crypto driver
+ */
+static int __init nss_crypto_module_init(void)
+{
+
+	nss_crypto_info_always("module loaded (platform - IPQ806x, %s)\n", NSS_CRYPTO_BUILD_ID);
+
+	nss_crypto_reset_state(&gbl_crypto_ctrl);
+
+	/*
+	 * bring the crypto out of reset
+	 */
+	iowrite32(0, CRYPTO_RESET_ENG(0));
+	iowrite32(0, CRYPTO_RESET_ENG(1));
+	iowrite32(0, CRYPTO_RESET_ENG(2));
+	iowrite32(0, CRYPTO_RESET_ENG(3));
+
+	iowrite32(0, CRYPTO_RESET_AHB);
+
+	nss_crypto_init();
+
+	nss_crypto_set_state(&gbl_crypto_ctrl, NSS_CRYPTO_STATE_READY);
+
+	nss_crypto_info_always("Register with NSS driver-\n");
+
+	INIT_DELAYED_WORK(&gbl_crypto_ctrl.crypto_work, nss_crypto_delayed_init);
+
+	schedule_delayed_work(&gbl_crypto_ctrl.crypto_work, msecs_to_jiffies(CRYPTO_DELAYED_INIT_TIME));
+
+	return 0;
+}
+
+module_init(nss_crypto_module_init);
+module_exit(nss_crypto_module_exit);
+
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_DESCRIPTION("QCA NSS Crypto driver");
-- 
cgit v1.1
